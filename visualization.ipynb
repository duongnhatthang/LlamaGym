{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2cc6d073-1157-4f34-8628-d1474ef97d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.labels to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.labels` for environment variables or `env.get_wrapper_attr('labels')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.spec to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.spec` for environment variables or `env.get_wrapper_attr('spec')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:175: UserWarning: \u001b[33mWARN: The default seed argument in `Env.reset` should be `None`, otherwise the environment will by default always be deterministic. Actual default: seed=0\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import d3rlpy\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from env.atari.represented_atari_game import GymCompatWrapper2\n",
    "from online_main import OneHotWrapper\n",
    "\n",
    "hyperparams = {\n",
    "        \"env\": \"RepresentedPong-v0\", #\"CartPole-v0\", \"MountainCar-v0\", \"FrozenLake-v1\", \"CliffWalking-v0\", \"RepresentedPong-v0\"\n",
    "        \"seed\": 42069,\n",
    "        \"n_episodes\": 300,\n",
    "        \"max_episode_len\": 200, # Around 10h per 100k steps in Leviathan server\n",
    "        \"eps\": 0.1,  # epsilon for exploration\n",
    "        \"n_exp\": 5,\n",
    "        \"n_pretrain_eps\": 30,\n",
    "        \"n_online_eps\": 270, #10-5990 for mountainCar, 30-120 for CartPole\n",
    "        \"gpu\": True, # True if use GPU to train with d3rlpy\n",
    "        \"buffer_size\": 100000, #Test with 100k, 200k, 500k. 1M might be too much\n",
    "        \"data_path\": None,#'data/CartPole_Qwen2.5-7B-Instruct_Neps_10_20250406040150.pkl',\n",
    "        \"model_path\": None,#'d3rlpy_loss/DoubleDQN_online_20250331153346/model_600000.d3',\n",
    "        \"batch_size\":256, #Test smaller batch size: 32, 64. May be noisier\n",
    "        \"learning_rate\":5e-5,\n",
    "        \"gamma\":0.99,\n",
    "        \"target_update_interval\":1000 #Test with 1k, 2k, 5k\n",
    "    }\n",
    "\n",
    "assert hyperparams[\"n_episodes\"]==hyperparams[\"n_pretrain_eps\"]+hyperparams[\"n_online_eps\"], \"Check n_episodes=n_pretrain_eps+n_online_eps\"\n",
    "\n",
    "if \"Represented\" in hyperparams[\"env\"]:\n",
    "    env = GymCompatWrapper2(gym.make(hyperparams[\"env\"]))\n",
    "    eval_env = GymCompatWrapper2(gym.make(hyperparams[\"env\"]))\n",
    "elif isinstance(gym.make(hyperparams[\"env\"]).observation_space, gym.spaces.Discrete):\n",
    "    env = OneHotWrapper(gym.make(hyperparams[\"env\"]))\n",
    "    eval_env = OneHotWrapper(gym.make(hyperparams[\"env\"]))\n",
    "else:\n",
    "    env = gym.make(hyperparams[\"env\"])\n",
    "    eval_env = gym.make(hyperparams[\"env\"])\n",
    "\n",
    "# fix seed\n",
    "d3rlpy.seed(hyperparams[\"seed\"])\n",
    "d3rlpy.envs.seed_env(env, hyperparams[\"seed\"])\n",
    "d3rlpy.envs.seed_env(eval_env, hyperparams[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700acf4-9af5-46f8-9fcf-24e3b7d8d2cd",
   "metadata": {},
   "source": [
    "### Static/pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "45a0488c-3f4d-43e2-a0c2-fd3a0d88b0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen_32B:  -4.966666666666667\n",
      "Qwen_7B:  -2.966666666666667\n"
     ]
    }
   ],
   "source": [
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250413234248.pkl\", 'rb') as file: #Pendulum\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250412171921.pkl\", 'rb') as file: #CliffWalking\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250412075104.pkl\", 'rb') as file: #FrozenLake\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250411000858.pkl\", 'rb') as file: #FrozenLakeBug\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250410211529.pkl\", 'rb') as file: #CartPole\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250409023954E.pkl\", 'rb') as file: #CartPoleE\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250415095844.pkl\", 'rb') as file: #MountainCar\n",
    "with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250420103044.pkl\", 'rb') as file: #RepresentedPong\n",
    "    Qwen_7B_dataset = pickle.load(file)\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250414014508.pkl\", 'rb') as file: #Pendulum\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250415065446.pkl\", 'rb') as file: #CliffWalking\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250412120230.pkl\", 'rb') as file: #FrozenLake\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250411030422.pkl\", 'rb') as file: #FrozenLakeBug\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250412032827.pkl\", 'rb') as file: #CartPole\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250409124533E.pkl\", 'rb') as file: #CartPoleE\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250413081613.pkl\", 'rb') as file: #MountainCar\n",
    "with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250420162547.pkl\", 'rb') as file: #RepresentedPong\n",
    "    Qwen_32B_dataset = pickle.load(file)\n",
    "\n",
    "Qwen_32B_rewards = []\n",
    "for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "    Qwen_32B_rewards.append(Qwen_32B_dataset.episodes[i].compute_return())\n",
    "Qwen_7B_rewards = []\n",
    "for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "    Qwen_7B_rewards.append(Qwen_7B_dataset.episodes[i].compute_return())\n",
    "\n",
    "Qwen_7B = Qwen_7B_rewards + hyperparams[\"n_online_eps\"] * [np.mean(Qwen_7B_rewards)]\n",
    "Qwen_32B = Qwen_32B_rewards + hyperparams[\"n_online_eps\"] * [np.mean(Qwen_32B_rewards)]\n",
    "\n",
    "print(\"Qwen_32B: \", np.mean(Qwen_7B_rewards))\n",
    "print(\"Qwen_7B: \", np.mean(Qwen_32B_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "78b9f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250421120400SFT.pkl\", 'rb') as file: #FrozenLake\n",
    "    with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250421175530SFT.pkl\", 'rb') as file: #CliffWalking\n",
    "    # with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250422210707SFT.pkl\", 'rb') as file: #Pendulum\n",
    "        Qwen_7B_SFT_dataset = pickle.load(file)\n",
    "\n",
    "    Qwen_7B_SFT_rewards = []\n",
    "    for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "        Qwen_7B_SFT_rewards.append(Qwen_7B_SFT_dataset.episodes[i].compute_return())\n",
    "    Qwen_7B_SFT = Qwen_7B_SFT_rewards + hyperparams[\"n_online_eps\"] * [np.mean(Qwen_7B_SFT_rewards)]\n",
    "    print(\"Qwen_7B_SFT: \", np.mean(Qwen_7B_SFT_rewards))\n",
    "except:\n",
    "    Qwen_7B_SFT = None\n",
    "try:\n",
    "    with open(f\"data/{hyperparams['env'].split('-')[0]}_DeepSeek-R1-Distill-Qwen-7B_Neps_{hyperparams['n_pretrain_eps']}_20250419172821.pkl\", 'rb') as file: #FrozenLake\n",
    "        DS_7B_dataset = pickle.load(file)\n",
    "    with open(f\"data/{hyperparams['env'].split('-')[0]}_DeepSeek-R1-Distill-Qwen-14B_Neps_{hyperparams['n_pretrain_eps']}_20250422000525.pkl\", 'rb') as file: #FrozenLake\n",
    "        DS_14B_dataset = pickle.load(file)\n",
    "    DS_7B_rewards = []\n",
    "    for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "        DS_7B_rewards.append(DS_7B_dataset.episodes[i].compute_return())\n",
    "    DS_14B_rewards = []\n",
    "    for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "        DS_14B_rewards.append(DS_14B_dataset.episodes[i].compute_return())\n",
    "\n",
    "    DS_7B = DS_7B_rewards + hyperparams[\"n_online_eps\"] * [np.mean(DS_7B_rewards)]\n",
    "    DS_14B = DS_14B_rewards + hyperparams[\"n_online_eps\"] * [np.mean(DS_14B_rewards)]\n",
    "\n",
    "    print(\"DS_7B: \", np.mean(DS_7B_rewards))\n",
    "    print(\"DS_14B: \", np.mean(DS_14B_rewards))\n",
    "except:\n",
    "    DS_7B = None\n",
    "    DS_14B = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa3e7b",
   "metadata": {},
   "source": [
    "### Generate and evaluate random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a1009e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:213: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for random policy: -4.4\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the random policy manually\n",
    "random_rewards = []\n",
    "for _ in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "\tobs, _ = env.reset()\n",
    "\tdone = False\n",
    "\ttotal_reward = 0\n",
    "\tcount = 0\n",
    "\twhile not done:\n",
    "\t\taction = env.action_space.sample()\n",
    "\t\tobs, reward, done, _, _ = env.step(action)\n",
    "\t\ttotal_reward += reward\n",
    "\t\tcount += 1\n",
    "\t\tif count >= hyperparams[\"max_episode_len\"]:\n",
    "\t\t\tbreak\n",
    "\trandom_rewards.append(total_reward)\n",
    "\n",
    "mean_random = np.ones(hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]) * np.mean(random_rewards)\n",
    "# Print the average reward of the random policy\n",
    "print(f\"Average reward for random policy: {mean_random[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778df60f-a837-4aec-a95a-7bb92e7ea615",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0fcb8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(hyperparams, Qwen_7B, Qwen_32B, DS_7B, DS_14B, Qwen_7B_SFT):\n",
    "    with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_10.pkl\", 'rb') as file:\n",
    "        cache10 = pickle.load(file)\n",
    "    with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_20.pkl\", 'rb') as file:\n",
    "        cache20 = pickle.load(file)\n",
    "    with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_30.pkl\", 'rb') as file:\n",
    "        cache30 = pickle.load(file)\n",
    "    with open(f'data/cache_{hyperparams[\"env\"].split(\"-\")[0]}_on_policy_pretrain_exp.pkl', 'rb') as file:\n",
    "        on_policy_pretrain_cache = pickle.load(file)\n",
    "    with open(f'data/cache_{hyperparams[\"env\"].split(\"-\")[0]}_on_policy_pretrain_exp_rand.pkl', 'rb') as file:\n",
    "        rand_pretrain_cache = pickle.load(file)\n",
    "    try:\n",
    "        with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_10SFT.pkl\", 'rb') as file:\n",
    "            cache10SFT = pickle.load(file)\n",
    "        with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_20SFT.pkl\", 'rb') as file:\n",
    "            cache20SFT = pickle.load(file)\n",
    "        with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_30SFT.pkl\", 'rb') as file:\n",
    "            cache30SFT = pickle.load(file)\n",
    "        pretrain_7b_1000_pre_10SFT_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_3000_pre_10SFT_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_1000_pre_20SFT_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_3000_pre_20SFT_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_1000_pre_30SFT_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_3000_pre_30SFT_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "\n",
    "        for i in range(hyperparams[\"n_exp\"]):\n",
    "            for j in range(hyperparams[\"n_episodes\"]-10):\n",
    "                pretrain_7b_1000_pre_10SFT_returns[i][10+j] = cache10SFT[f\"pretrain_7b_1000_{i}\"][j]\n",
    "                pretrain_7b_3000_pre_10SFT_returns[i][10+j] = cache10SFT[f\"pretrain_7b_3000_{i}\"][j]\n",
    "\n",
    "            for j in range(hyperparams[\"n_episodes\"]-20):\n",
    "                pretrain_7b_1000_pre_20SFT_returns[i][20+j] = cache20SFT[f\"pretrain_7b_1000_{i}\"][j]\n",
    "                pretrain_7b_3000_pre_20SFT_returns[i][20+j] = cache20SFT[f\"pretrain_7b_3000_{i}\"][j]\n",
    "\n",
    "            for j in range(hyperparams[\"n_episodes\"]-30):\n",
    "                pretrain_7b_1000_pre_30SFT_returns[i][30+j] = cache30SFT[f\"pretrain_7b_1000_{i}\"][j]\n",
    "                pretrain_7b_3000_pre_30SFT_returns[i][30+j] = cache30SFT[f\"pretrain_7b_3000_{i}\"][j]\n",
    "        mean_pretrain_7b_1000_pre_10SFT = np.mean(pretrain_7b_1000_pre_10SFT_returns, axis = 0)\n",
    "        std_pretrain_7b_1000_pre_10SFT = np.std(pretrain_7b_1000_pre_10SFT_returns, axis = 0)\n",
    "        mean_pretrain_7b_3000_pre_10SFT = np.mean(pretrain_7b_3000_pre_10SFT_returns, axis = 0)\n",
    "        std_pretrain_7b_3000_pre_10SFT = np.std(pretrain_7b_3000_pre_10SFT_returns, axis = 0)\n",
    "        mean_pretrain_7b_1000_pre_10SFT[:10] = Qwen_7B_SFT[:10]\n",
    "        mean_pretrain_7b_3000_pre_10SFT[:10] = Qwen_7B_SFT[:10]\n",
    "\n",
    "        mean_pretrain_7b_1000_pre_20SFT = np.mean(pretrain_7b_1000_pre_20SFT_returns, axis = 0)\n",
    "        std_pretrain_7b_1000_pre_20SFT = np.std(pretrain_7b_1000_pre_20SFT_returns, axis = 0)\n",
    "        mean_pretrain_7b_3000_pre_20SFT = np.mean(pretrain_7b_3000_pre_20SFT_returns, axis = 0)\n",
    "        std_pretrain_7b_3000_pre_20SFT = np.std(pretrain_7b_3000_pre_20SFT_returns, axis = 0)\n",
    "        mean_pretrain_7b_1000_pre_20SFT[:20] = Qwen_7B_SFT[:20]\n",
    "        mean_pretrain_7b_3000_pre_20SFT[:20] = Qwen_7B_SFT[:20]\n",
    "\n",
    "        mean_pretrain_7b_1000_pre_30SFT = np.mean(pretrain_7b_1000_pre_30SFT_returns, axis = 0)\n",
    "        std_pretrain_7b_1000_pre_30SFT = np.std(pretrain_7b_1000_pre_30SFT_returns, axis = 0)\n",
    "        mean_pretrain_7b_3000_pre_30SFT = np.mean(pretrain_7b_3000_pre_30SFT_returns, axis = 0)\n",
    "        std_pretrain_7b_3000_pre_30SFT = np.std(pretrain_7b_3000_pre_30SFT_returns, axis = 0)\n",
    "        mean_pretrain_7b_1000_pre_30SFT[:30] = Qwen_7B_SFT[:30]\n",
    "        mean_pretrain_7b_3000_pre_30SFT[:30] = Qwen_7B_SFT[:30]\n",
    "        out_dict_SFT = {\n",
    "            \"mean_pretrain_7b_1000_pre_10SFT\": mean_pretrain_7b_1000_pre_10SFT,\n",
    "            \"std_pretrain_7b_1000_pre_10SFT\": std_pretrain_7b_1000_pre_10SFT,\n",
    "            \"mean_pretrain_7b_3000_pre_10SFT\": mean_pretrain_7b_3000_pre_10SFT,\n",
    "            \"std_pretrain_7b_3000_pre_10SFT\": std_pretrain_7b_3000_pre_10SFT,\n",
    "            \"mean_pretrain_7b_1000_pre_20SFT\": mean_pretrain_7b_1000_pre_20SFT,\n",
    "            \"std_pretrain_7b_1000_pre_20SFT\": std_pretrain_7b_1000_pre_20SFT,\n",
    "            \"mean_pretrain_7b_3000_pre_20SFT\": mean_pretrain_7b_3000_pre_20SFT,\n",
    "            \"std_pretrain_7b_3000_pre_20SFT\": std_pretrain_7b_3000_pre_20SFT,\n",
    "            \"mean_pretrain_7b_1000_pre_30SFT\": mean_pretrain_7b_1000_pre_30SFT,\n",
    "            \"std_pretrain_7b_1000_pre_30SFT\": std_pretrain_7b_1000_pre_30SFT,\n",
    "            \"mean_pretrain_7b_3000_pre_30SFT\": mean_pretrain_7b_3000_pre_30SFT,\n",
    "            \"std_pretrain_7b_3000_pre_30SFT\": std_pretrain_7b_3000_pre_30SFT\n",
    "        }\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_10DS.pkl\", 'rb') as file:\n",
    "            cache10DS = pickle.load(file)\n",
    "        with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_20DS.pkl\", 'rb') as file:\n",
    "            cache20DS = pickle.load(file)\n",
    "        with open(f\"data/cache_{hyperparams['env'].split('-')[0]}_Neps_30DS.pkl\", 'rb') as file:\n",
    "            cache30DS = pickle.load(file)\n",
    "        pretrain_7b_1000_pre_10DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_3000_pre_10DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_14b_1000_pre_10DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_14b_3000_pre_10DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_1000_pre_20DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_3000_pre_20DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_14b_1000_pre_20DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_14b_3000_pre_20DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_1000_pre_30DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_7b_3000_pre_30DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_14b_1000_pre_30DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        pretrain_14b_3000_pre_30DS_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "        for i in range(hyperparams[\"n_exp\"]):\n",
    "            for j in range(hyperparams[\"n_episodes\"]-10):\n",
    "                pretrain_7b_1000_pre_10DS_returns[i][10+j] = cache10DS[f\"pretrain_7b_1000_{i}\"][j]\n",
    "                pretrain_14b_1000_pre_10DS_returns[i][10+j] = cache10DS[f\"pretrain_32b_1000_{i}\"][j]\n",
    "                pretrain_7b_3000_pre_10DS_returns[i][10+j] = cache10DS[f\"pretrain_7b_3000_{i}\"][j]\n",
    "                pretrain_14b_3000_pre_10DS_returns[i][10+j] = cache10DS[f\"pretrain_32b_3000_{i}\"][j]\n",
    "\n",
    "            for j in range(hyperparams[\"n_episodes\"]-20):\n",
    "                pretrain_7b_1000_pre_20DS_returns[i][20+j] = cache20DS[f\"pretrain_7b_1000_{i}\"][j]\n",
    "                pretrain_14b_1000_pre_20DS_returns[i][20+j] = cache20DS[f\"pretrain_32b_1000_{i}\"][j]\n",
    "                pretrain_7b_3000_pre_20DS_returns[i][20+j] = cache20DS[f\"pretrain_7b_3000_{i}\"][j]\n",
    "                pretrain_14b_3000_pre_20DS_returns[i][20+j] = cache20DS[f\"pretrain_32b_3000_{i}\"][j]\n",
    "\n",
    "            for j in range(hyperparams[\"n_episodes\"]-30):\n",
    "                pretrain_7b_1000_pre_30DS_returns[i][30+j] = cache30DS[f\"pretrain_7b_1000_{i}\"][j]\n",
    "                pretrain_14b_1000_pre_30DS_returns[i][30+j] = cache30DS[f\"pretrain_32b_1000_{i}\"][j]\n",
    "                pretrain_7b_3000_pre_30DS_returns[i][30+j] = cache30DS[f\"pretrain_7b_3000_{i}\"][j]\n",
    "                pretrain_14b_3000_pre_30DS_returns[i][30+j] = cache30DS[f\"pretrain_32b_3000_{i}\"][j]\n",
    "        mean_pretrain_7b_1000_pre_10DS = np.mean(pretrain_7b_1000_pre_10DS_returns, axis = 0)\n",
    "        std_pretrain_7b_1000_pre_10DS = np.std(pretrain_7b_1000_pre_10DS_returns, axis = 0)\n",
    "        mean_pretrain_7b_3000_pre_10DS = np.mean(pretrain_7b_3000_pre_10DS_returns, axis = 0)\n",
    "        std_pretrain_7b_3000_pre_10DS = np.std(pretrain_7b_3000_pre_10DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_1000_pre_10DS = np.mean(pretrain_14b_1000_pre_10DS_returns, axis = 0)\n",
    "        std_pretrain_14b_1000_pre_10DS = np.std(pretrain_14b_1000_pre_10DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_3000_pre_10DS = np.mean(pretrain_14b_3000_pre_10DS_returns, axis = 0)\n",
    "        std_pretrain_14b_3000_pre_10DS = np.std(pretrain_14b_3000_pre_10DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_1000_pre_10DS[:10] = DS_14B[:10]\n",
    "        mean_pretrain_7b_1000_pre_10DS[:10] = DS_7B[:10]\n",
    "        mean_pretrain_14b_3000_pre_10DS[:10] = DS_14B[:10]\n",
    "        mean_pretrain_7b_3000_pre_10DS[:10] = DS_7B[:10]\n",
    "\n",
    "        mean_pretrain_7b_1000_pre_20DS = np.mean(pretrain_7b_1000_pre_20DS_returns, axis = 0)\n",
    "        std_pretrain_7b_1000_pre_20DS = np.std(pretrain_7b_1000_pre_20DS_returns, axis = 0)\n",
    "        mean_pretrain_7b_3000_pre_20DS = np.mean(pretrain_7b_3000_pre_20DS_returns, axis = 0)\n",
    "        std_pretrain_7b_3000_pre_20DS = np.std(pretrain_7b_3000_pre_20DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_1000_pre_20DS = np.mean(pretrain_14b_1000_pre_20DS_returns, axis = 0)\n",
    "        std_pretrain_14b_1000_pre_20DS = np.std(pretrain_14b_1000_pre_20DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_3000_pre_20DS = np.mean(pretrain_14b_3000_pre_20DS_returns, axis = 0)\n",
    "        std_pretrain_14b_3000_pre_20DS = np.std(pretrain_14b_3000_pre_20DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_1000_pre_20DS[:20] = DS_14B[:20]\n",
    "        mean_pretrain_7b_1000_pre_20DS[:20] = DS_7B[:20]\n",
    "        mean_pretrain_14b_3000_pre_20DS[:20] = DS_14B[:20]\n",
    "        mean_pretrain_7b_3000_pre_20DS[:20] = DS_7B[:20]\n",
    "\n",
    "        mean_pretrain_7b_1000_pre_30DS = np.mean(pretrain_7b_1000_pre_30DS_returns, axis = 0)\n",
    "        std_pretrain_7b_1000_pre_30DS = np.std(pretrain_7b_1000_pre_30DS_returns, axis = 0)\n",
    "        mean_pretrain_7b_3000_pre_30DS = np.mean(pretrain_7b_3000_pre_30DS_returns, axis = 0)\n",
    "        std_pretrain_7b_3000_pre_30DS = np.std(pretrain_7b_3000_pre_30DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_1000_pre_30DS = np.mean(pretrain_14b_1000_pre_30DS_returns, axis = 0)\n",
    "        std_pretrain_14b_1000_pre_30DS = np.std(pretrain_14b_1000_pre_30DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_3000_pre_30DS = np.mean(pretrain_14b_3000_pre_30DS_returns, axis = 0)\n",
    "        std_pretrain_14b_3000_pre_30DS = np.std(pretrain_14b_3000_pre_30DS_returns, axis = 0)\n",
    "        mean_pretrain_14b_1000_pre_30DS[:30] = DS_14B[:30]\n",
    "        mean_pretrain_7b_1000_pre_30DS[:30] = DS_7B[:30]\n",
    "        mean_pretrain_14b_3000_pre_30DS[:30] = DS_14B[:30]\n",
    "        mean_pretrain_7b_3000_pre_30DS[:30] = DS_7B[:30]\n",
    "        out_dict_DS = {\n",
    "            \"mean_pretrain_7b_1000_pre_10DS\": mean_pretrain_7b_1000_pre_10DS,\n",
    "            \"std_pretrain_7b_1000_pre_10DS\": std_pretrain_7b_1000_pre_10DS,\n",
    "            \"mean_pretrain_7b_3000_pre_10DS\": mean_pretrain_7b_3000_pre_10DS,\n",
    "            \"std_pretrain_7b_3000_pre_10DS\": std_pretrain_7b_3000_pre_10DS,\n",
    "            \"mean_pretrain_14b_1000_pre_10DS\": mean_pretrain_14b_1000_pre_10DS,\n",
    "            \"std_pretrain_14b_1000_pre_10DS\": std_pretrain_14b_1000_pre_10DS,\n",
    "            \"mean_pretrain_14b_3000_pre_10DS\": mean_pretrain_14b_3000_pre_10DS,\n",
    "            \"std_pretrain_14b_3000_pre_10DS\": std_pretrain_14b_3000_pre_10DS,\n",
    "            \"mean_pretrain_7b_1000_pre_20DS\": mean_pretrain_7b_1000_pre_20DS,\n",
    "            \"std_pretrain_7b_1000_pre_20DS\": std_pretrain_7b_1000_pre_20DS,\n",
    "            \"mean_pretrain_7b_3000_pre_20DS\": mean_pretrain_7b_3000_pre_20DS,\n",
    "            \"std_pretrain_7b_3000_pre_20DS\": std_pretrain_7b_3000_pre_20DS,\n",
    "            \"mean_pretrain_14b_1000_pre_20DS\": mean_pretrain_14b_1000_pre_20DS,\n",
    "            \"std_pretrain_14b_1000_pre_20DS\": std_pretrain_14b_1000_pre_20DS,\n",
    "            \"mean_pretrain_14b_3000_pre_20DS\": mean_pretrain_14b_3000_pre_20DS,\n",
    "            \"std_pretrain_14b_3000_pre_20DS\": std_pretrain_14b_3000_pre_20DS,\n",
    "            \"mean_pretrain_7b_1000_pre_30DS\": mean_pretrain_7b_1000_pre_30DS,\n",
    "            \"std_pretrain_7b_1000_pre_30DS\": std_pretrain_7b_1000_pre_30DS,\n",
    "            \"mean_pretrain_7b_3000_pre_30DS\": mean_pretrain_7b_3000_pre_30DS,\n",
    "            \"std_pretrain_7b_3000_pre_30DS\": std_pretrain_7b_3000_pre_30DS,\n",
    "            \"mean_pretrain_14b_1000_pre_30DS\": mean_pretrain_14b_1000_pre_30DS,\n",
    "            \"std_pretrain_14b_1000_pre_30DS\": std_pretrain_14b_1000_pre_30DS,\n",
    "            \"mean_pretrain_14b_3000_pre_30DS\": mean_pretrain_14b_3000_pre_30DS,\n",
    "            \"std_pretrain_14b_3000_pre_30DS\": std_pretrain_14b_3000_pre_30DS\n",
    "        }\n",
    "    except:\n",
    "        pass\n",
    "    online_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    mix_7b_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    mix_32b_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_7b_1000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_32b_1000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_7b_3000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_32b_3000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    on_pol_pretrain_1000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    on_pol_pretrain_3000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    rand_pretrain_1000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    rand_pretrain_3000_pre_10_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "\n",
    "    mix_7b_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    mix_32b_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_7b_1000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_32b_1000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_7b_3000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_32b_3000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    on_pol_pretrain_1000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    on_pol_pretrain_3000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    rand_pretrain_1000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    rand_pretrain_3000_pre_20_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "\n",
    "    mix_7b_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    mix_32b_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_7b_1000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_32b_1000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_7b_3000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    pretrain_32b_3000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    on_pol_pretrain_1000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    on_pol_pretrain_3000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    rand_pretrain_1000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "    rand_pretrain_3000_pre_30_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_episodes\"]))\n",
    "\n",
    "    for i in range(hyperparams[\"n_exp\"]):\n",
    "        # online_returns[i] = cache10[f\"online_{i}\"]\n",
    "        online_returns[i] = cache10[f\"online_{i}\"][:hyperparams[\"n_episodes\"]] #Quick-fix for MountainCar\n",
    "        on_pol_pretrain_1000_pre_10_returns[i] = on_policy_pretrain_cache[f'pretrain_10_eps_1000_steps_{i}']\n",
    "        on_pol_pretrain_3000_pre_10_returns[i] = on_policy_pretrain_cache[f'pretrain_10_eps_3000_steps_{i}']\n",
    "        on_pol_pretrain_1000_pre_20_returns[i] = on_policy_pretrain_cache[f'pretrain_20_eps_1000_steps_{i}']\n",
    "        on_pol_pretrain_3000_pre_20_returns[i] = on_policy_pretrain_cache[f'pretrain_20_eps_3000_steps_{i}']\n",
    "        on_pol_pretrain_1000_pre_30_returns[i] = on_policy_pretrain_cache[f'pretrain_30_eps_1000_steps_{i}']\n",
    "        on_pol_pretrain_3000_pre_30_returns[i] = on_policy_pretrain_cache[f'pretrain_30_eps_3000_steps_{i}']\n",
    "\n",
    "        rand_pretrain_1000_pre_10_returns[i] = rand_pretrain_cache[f'pretrain_10_eps_1000_steps_{i}_rand']\n",
    "        rand_pretrain_3000_pre_10_returns[i] = rand_pretrain_cache[f'pretrain_10_eps_3000_steps_{i}_rand']\n",
    "        rand_pretrain_1000_pre_20_returns[i] = rand_pretrain_cache[f'pretrain_20_eps_1000_steps_{i}_rand']\n",
    "        rand_pretrain_3000_pre_20_returns[i] = rand_pretrain_cache[f'pretrain_20_eps_3000_steps_{i}_rand']\n",
    "        rand_pretrain_1000_pre_30_returns[i] = rand_pretrain_cache[f'pretrain_30_eps_1000_steps_{i}_rand']\n",
    "        rand_pretrain_3000_pre_30_returns[i] = rand_pretrain_cache[f'pretrain_30_eps_3000_steps_{i}_rand']\n",
    "        for j in range(hyperparams[\"n_episodes\"]-10):\n",
    "            mix_7b_pre_10_returns[i][10+j] = cache10[f\"finetune_7b_{i}\"][j]\n",
    "            mix_32b_pre_10_returns[i][10+j] = cache10[f\"finetune_32b_{i}\"][j]\n",
    "            pretrain_7b_1000_pre_10_returns[i][10+j] = cache10[f\"pretrain_7b_1000_{i}\"][j]\n",
    "            pretrain_32b_1000_pre_10_returns[i][10+j] = cache10[f\"pretrain_32b_1000_{i}\"][j]\n",
    "            pretrain_7b_3000_pre_10_returns[i][10+j] = cache10[f\"pretrain_7b_3000_{i}\"][j]\n",
    "            pretrain_32b_3000_pre_10_returns[i][10+j] = cache10[f\"pretrain_32b_3000_{i}\"][j]\n",
    "\n",
    "        for j in range(hyperparams[\"n_episodes\"]-20):\n",
    "            mix_7b_pre_20_returns[i][20+j] = cache20[f\"finetune_7b_{i}\"][j]\n",
    "            mix_32b_pre_20_returns[i][20+j] = cache20[f\"finetune_32b_{i}\"][j]\n",
    "            pretrain_7b_1000_pre_20_returns[i][20+j] = cache20[f\"pretrain_7b_1000_{i}\"][j]\n",
    "            pretrain_32b_1000_pre_20_returns[i][20+j] = cache20[f\"pretrain_32b_1000_{i}\"][j]\n",
    "            pretrain_7b_3000_pre_20_returns[i][20+j] = cache20[f\"pretrain_7b_3000_{i}\"][j]\n",
    "            pretrain_32b_3000_pre_20_returns[i][20+j] = cache20[f\"pretrain_32b_3000_{i}\"][j]\n",
    "\n",
    "        for j in range(hyperparams[\"n_episodes\"]-30):\n",
    "            mix_7b_pre_30_returns[i][30+j] = cache30[f\"finetune_7b_{i}\"][j]\n",
    "            mix_32b_pre_30_returns[i][30+j] = cache30[f\"finetune_32b_{i}\"][j]\n",
    "            pretrain_7b_1000_pre_30_returns[i][30+j] = cache30[f\"pretrain_7b_1000_{i}\"][j]\n",
    "            pretrain_32b_1000_pre_30_returns[i][30+j] = cache30[f\"pretrain_32b_1000_{i}\"][j]\n",
    "            pretrain_7b_3000_pre_30_returns[i][30+j] = cache30[f\"pretrain_7b_3000_{i}\"][j]\n",
    "            pretrain_32b_3000_pre_30_returns[i][30+j] = cache30[f\"pretrain_32b_3000_{i}\"][j]\n",
    "\n",
    "    x = range(hyperparams[\"n_episodes\"])\n",
    "\n",
    "    mean_mix_32b_pre_10 = np.mean(mix_32b_pre_10_returns, axis = 0)\n",
    "    std_mix_32b_pre_10 = np.std(mix_32b_pre_10_returns, axis = 0)\n",
    "    mean_mix_7b_pre_10 = np.mean(mix_7b_pre_10_returns, axis = 0)\n",
    "    std_mix_7b_pre_10 = np.std(mix_7b_pre_10_returns, axis = 0)\n",
    "    mean_onl = np.mean(online_returns, axis = 0)\n",
    "    std_onl = np.std(online_returns, axis = 0)\n",
    "    mean_pretrain_32b_1000_pre_10 = np.mean(pretrain_32b_1000_pre_10_returns, axis = 0)\n",
    "    std_pretrain_32b_1000_pre_10 = np.std(pretrain_32b_1000_pre_10_returns, axis = 0)\n",
    "    mean_pretrain_7b_1000_pre_10 = np.mean(pretrain_7b_1000_pre_10_returns, axis = 0)\n",
    "    std_pretrain_7b_1000_pre_10 = np.std(pretrain_7b_1000_pre_10_returns, axis = 0)\n",
    "    mean_pretrain_32b_3000_pre_10 = np.mean(pretrain_32b_3000_pre_10_returns, axis = 0)\n",
    "    std_pretrain_32b_3000_pre_10 = np.std(pretrain_32b_3000_pre_10_returns, axis = 0)\n",
    "    mean_pretrain_7b_3000_pre_10 = np.mean(pretrain_7b_3000_pre_10_returns, axis = 0)\n",
    "    std_pretrain_7b_3000_pre_10 = np.std(pretrain_7b_3000_pre_10_returns, axis = 0)\n",
    "    mean_on_pol_pretrain_1000_pre_10 = np.mean(on_pol_pretrain_1000_pre_10_returns, axis = 0)\n",
    "    std_on_pol_pretrain_1000_pre_10 = np.std(on_pol_pretrain_1000_pre_10_returns, axis = 0)\n",
    "    mean_on_pol_pretrain_3000_pre_10 = np.mean(on_pol_pretrain_3000_pre_10_returns, axis = 0)\n",
    "    std_on_pol_pretrain_3000_pre_10 = np.std(on_pol_pretrain_3000_pre_10_returns, axis = 0)\n",
    "    mean_rand_pretrain_1000_pre_10 = np.mean(rand_pretrain_1000_pre_10_returns, axis = 0)\n",
    "    std_rand_pretrain_1000_pre_10 = np.std(rand_pretrain_1000_pre_10_returns, axis = 0)\n",
    "    mean_rand_pretrain_3000_pre_10 = np.mean(rand_pretrain_3000_pre_10_returns, axis = 0)\n",
    "    std_rand_pretrain_3000_pre_10 = np.std(rand_pretrain_3000_pre_10_returns, axis = 0)\n",
    "\n",
    "    mean_mix_7b_pre_10[:10] = Qwen_7B[:10]\n",
    "    mean_mix_32b_pre_10[:10] = Qwen_32B[:10]\n",
    "    mean_pretrain_32b_1000_pre_10[:10] = Qwen_32B[:10]\n",
    "    mean_pretrain_7b_1000_pre_10[:10] = Qwen_7B[:10]\n",
    "    mean_pretrain_32b_3000_pre_10[:10] = Qwen_32B[:10]\n",
    "    mean_pretrain_7b_3000_pre_10[:10] = Qwen_7B[:10]\n",
    "\n",
    "    mean_mix_32b_pre_20 = np.mean(mix_32b_pre_20_returns, axis = 0)\n",
    "    std_mix_32b_pre_20 = np.std(mix_32b_pre_20_returns, axis = 0)\n",
    "    mean_mix_7b_pre_20 = np.mean(mix_7b_pre_20_returns, axis = 0)\n",
    "    std_mix_7b_pre_20 = np.std(mix_7b_pre_20_returns, axis = 0)\n",
    "    mean_pretrain_32b_1000_pre_20 = np.mean(pretrain_32b_1000_pre_20_returns, axis = 0)\n",
    "    std_pretrain_32b_1000_pre_20 = np.std(pretrain_32b_1000_pre_20_returns, axis = 0)\n",
    "    mean_pretrain_7b_1000_pre_20 = np.mean(pretrain_7b_1000_pre_20_returns, axis = 0)\n",
    "    std_pretrain_7b_1000_pre_20 = np.std(pretrain_7b_1000_pre_20_returns, axis = 0)\n",
    "    mean_pretrain_32b_3000_pre_20 = np.mean(pretrain_32b_3000_pre_20_returns, axis = 0)\n",
    "    std_pretrain_32b_3000_pre_20 = np.std(pretrain_32b_3000_pre_20_returns, axis = 0)\n",
    "    mean_pretrain_7b_3000_pre_20 = np.mean(pretrain_7b_3000_pre_20_returns, axis = 0)\n",
    "    std_pretrain_7b_3000_pre_20 = np.std(pretrain_7b_3000_pre_20_returns, axis = 0)\n",
    "    mean_on_pol_pretrain_1000_pre_20 = np.mean(on_pol_pretrain_1000_pre_20_returns, axis = 0)\n",
    "    std_on_pol_pretrain_1000_pre_20 = np.std(on_pol_pretrain_1000_pre_20_returns, axis = 0)\n",
    "    mean_on_pol_pretrain_3000_pre_20 = np.mean(on_pol_pretrain_3000_pre_20_returns, axis = 0)\n",
    "    std_on_pol_pretrain_3000_pre_20 = np.std(on_pol_pretrain_3000_pre_20_returns, axis = 0)\n",
    "    mean_rand_pretrain_1000_pre_20 = np.mean(rand_pretrain_1000_pre_20_returns, axis = 0)\n",
    "    std_rand_pretrain_1000_pre_20 = np.std(rand_pretrain_1000_pre_20_returns, axis = 0)\n",
    "    mean_rand_pretrain_3000_pre_20 = np.mean(rand_pretrain_3000_pre_20_returns, axis = 0)\n",
    "    std_rand_pretrain_3000_pre_20 = np.std(rand_pretrain_3000_pre_20_returns, axis = 0)\n",
    "\n",
    "    mean_mix_7b_pre_20[:20] = Qwen_7B[:20]\n",
    "    mean_mix_32b_pre_20[:20] = Qwen_32B[:20]\n",
    "    mean_pretrain_32b_1000_pre_20[:20] = Qwen_32B[:20]\n",
    "    mean_pretrain_7b_1000_pre_20[:20] = Qwen_7B[:20]\n",
    "    mean_pretrain_32b_3000_pre_20[:20] = Qwen_32B[:20]\n",
    "    mean_pretrain_7b_3000_pre_20[:20] = Qwen_7B[:20]\n",
    "\n",
    "    mean_mix_32b_pre_30 = np.mean(mix_32b_pre_30_returns, axis = 0)\n",
    "    std_mix_32b_pre_30 = np.std(mix_32b_pre_30_returns, axis = 0)\n",
    "    mean_mix_7b_pre_30 = np.mean(mix_7b_pre_30_returns, axis = 0)\n",
    "    std_mix_7b_pre_30 = np.std(mix_7b_pre_30_returns, axis = 0)\n",
    "    mean_pretrain_32b_1000_pre_30 = np.mean(pretrain_32b_1000_pre_30_returns, axis = 0)\n",
    "    std_pretrain_32b_1000_pre_30 = np.std(pretrain_32b_1000_pre_30_returns, axis = 0)\n",
    "    mean_pretrain_7b_1000_pre_30 = np.mean(pretrain_7b_1000_pre_30_returns, axis = 0)\n",
    "    std_pretrain_7b_1000_pre_30 = np.std(pretrain_7b_1000_pre_30_returns, axis = 0)\n",
    "    mean_pretrain_32b_3000_pre_30 = np.mean(pretrain_32b_3000_pre_30_returns, axis = 0)\n",
    "    std_pretrain_32b_3000_pre_30 = np.std(pretrain_32b_3000_pre_30_returns, axis = 0)\n",
    "    mean_pretrain_7b_3000_pre_30 = np.mean(pretrain_7b_3000_pre_30_returns, axis = 0)\n",
    "    std_pretrain_7b_3000_pre_30 = np.std(pretrain_7b_3000_pre_30_returns, axis = 0)\n",
    "    mean_on_pol_pretrain_1000_pre_30 = np.mean(on_pol_pretrain_1000_pre_30_returns, axis = 0)\n",
    "    std_on_pol_pretrain_1000_pre_30 = np.std(on_pol_pretrain_1000_pre_30_returns, axis = 0)\n",
    "    mean_on_pol_pretrain_3000_pre_30 = np.mean(on_pol_pretrain_3000_pre_30_returns, axis = 0)\n",
    "    std_on_pol_pretrain_3000_pre_30 = np.std(on_pol_pretrain_3000_pre_30_returns, axis = 0)\n",
    "    mean_rand_pretrain_1000_pre_30 = np.mean(rand_pretrain_1000_pre_30_returns, axis = 0)\n",
    "    std_rand_pretrain_1000_pre_30 = np.std(rand_pretrain_1000_pre_30_returns, axis = 0)\n",
    "    mean_rand_pretrain_3000_pre_30 = np.mean(rand_pretrain_3000_pre_30_returns, axis = 0)\n",
    "    std_rand_pretrain_3000_pre_30 = np.std(rand_pretrain_3000_pre_30_returns, axis = 0)\n",
    "\n",
    "    mean_mix_7b_pre_30[:30] = Qwen_7B[:30]\n",
    "    mean_mix_32b_pre_30[:30] = Qwen_32B[:30]\n",
    "    mean_pretrain_32b_1000_pre_30[:30] = Qwen_32B[:30]\n",
    "    mean_pretrain_7b_1000_pre_30[:30] = Qwen_7B[:30]\n",
    "    mean_pretrain_32b_3000_pre_30[:30] = Qwen_32B[:30]\n",
    "    mean_pretrain_7b_3000_pre_30[:30] = Qwen_7B[:30]\n",
    "\n",
    "    out_dict = {\n",
    "        \"x\": x,\n",
    "        \"mean_onl\": mean_onl,\n",
    "        \"std_onl\": std_onl,\n",
    "        \"Qwen_7B\": Qwen_7B,\n",
    "        \"Qwen_32B\": Qwen_32B,\n",
    "        \"mean_random\": mean_random,\n",
    "        \"mean_mix_7b_pre_10\": mean_mix_7b_pre_10,\n",
    "        \"mean_mix_32b_pre_10\": mean_mix_32b_pre_10,\n",
    "        \"mean_pretrain_32b_1000_pre_10\": mean_pretrain_32b_1000_pre_10,\n",
    "        \"mean_pretrain_7b_1000_pre_10\": mean_pretrain_7b_1000_pre_10,\n",
    "        \"mean_pretrain_32b_3000_pre_10\": mean_pretrain_32b_3000_pre_10,\n",
    "        \"mean_pretrain_7b_3000_pre_10\": mean_pretrain_7b_3000_pre_10,\n",
    "        \"std_mix_32b_pre_10\": std_mix_32b_pre_10,\n",
    "        \"std_mix_7b_pre_10\": std_mix_7b_pre_10,\n",
    "        \"std_pretrain_32b_1000_pre_10\": std_pretrain_32b_1000_pre_10,\n",
    "        \"std_pretrain_7b_1000_pre_10\": std_pretrain_7b_1000_pre_10,\n",
    "        \"std_pretrain_32b_3000_pre_10\": std_pretrain_32b_3000_pre_10,\n",
    "        \"std_pretrain_7b_3000_pre_10\": std_pretrain_7b_3000_pre_10,\n",
    "        \"mean_on_pol_pretrain_1000_pre_10\": mean_on_pol_pretrain_1000_pre_10,\n",
    "        \"std_on_pol_pretrain_1000_pre_10\": std_on_pol_pretrain_1000_pre_10,\n",
    "        \"mean_on_pol_pretrain_3000_pre_10\": mean_on_pol_pretrain_3000_pre_10,\n",
    "        \"std_on_pol_pretrain_3000_pre_10\": std_on_pol_pretrain_3000_pre_10,\n",
    "        \"mean_rand_pretrain_1000_pre_10\": mean_rand_pretrain_1000_pre_10,\n",
    "        \"std_rand_pretrain_1000_pre_10\": std_rand_pretrain_1000_pre_10,\n",
    "        \"mean_rand_pretrain_3000_pre_10\": mean_rand_pretrain_3000_pre_10,\n",
    "        \"std_rand_pretrain_3000_pre_10\": std_rand_pretrain_3000_pre_10,\n",
    "        \"mean_mix_7b_pre_20\": mean_mix_7b_pre_20, #20 here\n",
    "        \"mean_mix_32b_pre_20\": mean_mix_32b_pre_20,\n",
    "        \"mean_pretrain_32b_1000_pre_20\": mean_pretrain_32b_1000_pre_20,\n",
    "        \"mean_pretrain_7b_1000_pre_20\": mean_pretrain_7b_1000_pre_20,\n",
    "        \"mean_pretrain_32b_3000_pre_20\": mean_pretrain_32b_3000_pre_20,\n",
    "        \"mean_pretrain_7b_3000_pre_20\": mean_pretrain_7b_3000_pre_20,\n",
    "        \"std_mix_32b_pre_20\": std_mix_32b_pre_20,\n",
    "        \"std_mix_7b_pre_20\": std_mix_7b_pre_20,\n",
    "        \"std_pretrain_32b_1000_pre_20\": std_pretrain_32b_1000_pre_20,\n",
    "        \"std_pretrain_7b_1000_pre_20\": std_pretrain_7b_1000_pre_20,\n",
    "        \"std_pretrain_32b_3000_pre_20\": std_pretrain_32b_3000_pre_20,\n",
    "        \"std_pretrain_7b_3000_pre_20\": std_pretrain_7b_3000_pre_20,\n",
    "        \"mean_on_pol_pretrain_1000_pre_20\": mean_on_pol_pretrain_1000_pre_20,\n",
    "        \"std_on_pol_pretrain_1000_pre_20\": std_on_pol_pretrain_1000_pre_20,\n",
    "        \"mean_on_pol_pretrain_3000_pre_20\": mean_on_pol_pretrain_3000_pre_20,\n",
    "        \"std_on_pol_pretrain_3000_pre_20\": std_on_pol_pretrain_3000_pre_20,\n",
    "        \"mean_rand_pretrain_1000_pre_20\": mean_rand_pretrain_1000_pre_20,\n",
    "        \"std_rand_pretrain_1000_pre_20\": std_rand_pretrain_1000_pre_20,\n",
    "        \"mean_rand_pretrain_3000_pre_20\": mean_rand_pretrain_3000_pre_20,\n",
    "        \"std_rand_pretrain_3000_pre_20\": std_rand_pretrain_3000_pre_20,\n",
    "        \"mean_mix_7b_pre_30\": mean_mix_7b_pre_30, #30 here\n",
    "        \"mean_mix_32b_pre_30\": mean_mix_32b_pre_30,\n",
    "        \"mean_pretrain_32b_1000_pre_30\": mean_pretrain_32b_1000_pre_30,\n",
    "        \"mean_pretrain_7b_1000_pre_30\": mean_pretrain_7b_1000_pre_30,\n",
    "        \"mean_pretrain_32b_3000_pre_30\": mean_pretrain_32b_3000_pre_30,\n",
    "        \"mean_pretrain_7b_3000_pre_30\": mean_pretrain_7b_3000_pre_30,\n",
    "        \"std_mix_32b_pre_30\": std_mix_32b_pre_30,\n",
    "        \"std_mix_7b_pre_30\": std_mix_7b_pre_30,\n",
    "        \"std_pretrain_32b_1000_pre_30\": std_pretrain_32b_1000_pre_30,\n",
    "        \"std_pretrain_7b_1000_pre_30\": std_pretrain_7b_1000_pre_30,\n",
    "        \"std_pretrain_32b_3000_pre_30\": std_pretrain_32b_3000_pre_30,\n",
    "        \"std_pretrain_7b_3000_pre_30\": std_pretrain_7b_3000_pre_30,\n",
    "        \"mean_on_pol_pretrain_1000_pre_30\": mean_on_pol_pretrain_1000_pre_30,\n",
    "        \"std_on_pol_pretrain_1000_pre_30\": std_on_pol_pretrain_1000_pre_30,\n",
    "        \"mean_on_pol_pretrain_3000_pre_30\": mean_on_pol_pretrain_3000_pre_30,\n",
    "        \"std_on_pol_pretrain_3000_pre_30\": std_on_pol_pretrain_3000_pre_30,\n",
    "        \"mean_rand_pretrain_1000_pre_30\": mean_rand_pretrain_1000_pre_30,\n",
    "        \"std_rand_pretrain_1000_pre_30\": std_rand_pretrain_1000_pre_30,\n",
    "        \"mean_rand_pretrain_3000_pre_30\": mean_rand_pretrain_3000_pre_30,\n",
    "        \"std_rand_pretrain_3000_pre_30\": std_rand_pretrain_3000_pre_30\n",
    "    }\n",
    "    try:\n",
    "        for k,v in out_dict_SFT.items():\n",
    "            out_dict[k] = v\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for k,v in out_dict_DS.items():\n",
    "            out_dict[k] = v\n",
    "    except:\n",
    "        pass\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6b6ed401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_main(hyperparams, cache):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cache['mean_onl'], label='On-policy')\n",
    "    plt.fill_between(cache['x'], cache['mean_onl']-cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_onl']+cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    plt.plot(cache['mean_pretrain_7b_3000_pre_10'], label='LORO')\n",
    "    plt.fill_between(cache['x'], cache['mean_pretrain_7b_3000_pre_10']-cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_7b_3000_pre_10'] +cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "\n",
    "    plt.plot(Qwen_7B, label='Qwen_7B', linestyle=':')\n",
    "    plt.plot(Qwen_32B, label='Qwen_32B', linestyle=':')\n",
    "    plt.plot(mean_random, label='Random', linestyle=':')\n",
    "\n",
    "    plt.title(f'{hyperparams[\"env\"].split(\"-\")[0]} episode reward with std error for {hyperparams[\"n_exp\"]} seeds.')\n",
    "    plt.xlabel('# of episodes')\n",
    "    plt.ylabel('Episode reward')\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.grid(True)\n",
    "    # plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    if \"Cliff\" in hyperparams[\"env\"]:\n",
    "        plt.ylim(-500, 0)\n",
    "    if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "        plt.ylim(-250, -100)\n",
    "    # plt.xticks(np.arange(0, 101, 10))\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_main.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_pretrain(hyperparams, cache):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cache['mean_onl'], label='On-policy')\n",
    "    plt.fill_between(cache['x'], cache['mean_onl']-cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_onl']+cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    plt.plot(cache['mean_pretrain_7b_3000_pre_10'], label='LORO')\n",
    "    plt.fill_between(cache['x'], cache['mean_pretrain_7b_3000_pre_10']-cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_7b_3000_pre_10'] +cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    plt.plot(cache['mean_on_pol_pretrain_3000_pre_10'], label='Pretrain w/ On-policy data')\n",
    "    plt.fill_between(cache['x'], cache['mean_on_pol_pretrain_3000_pre_10']-cache['std_on_pol_pretrain_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_on_pol_pretrain_3000_pre_10'] +cache['std_on_pol_pretrain_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    plt.plot(cache['mean_rand_pretrain_3000_pre_10'], label='Pretrain w/ random policy data')\n",
    "    plt.fill_between(cache['x'], cache['mean_rand_pretrain_3000_pre_10']-cache['std_rand_pretrain_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_rand_pretrain_3000_pre_10'] +cache['std_rand_pretrain_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "\n",
    "    plt.title(f'{hyperparams[\"env\"].split(\"-\")[0]} episode reward with std error for {hyperparams[\"n_exp\"]} seeds.')\n",
    "    plt.xlabel('# of episodes')\n",
    "    plt.ylabel('Episode reward')\n",
    "    if \"Cliff\" in hyperparams[\"env\"] or \"MountainCar\" in hyperparams[\"env\"]:\n",
    "        plt.ylim(-500, 0)\n",
    "    if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "        plt.ylim(-250, -100)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_pretrain.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_mix(hyperparams, cache):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cache['mean_onl'], label='On-policy')\n",
    "    plt.fill_between(cache['x'], cache['mean_onl']-cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_onl']+cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    plt.plot(cache['mean_pretrain_7b_3000_pre_10'], label='LORO')\n",
    "    plt.fill_between(cache['x'], cache['mean_pretrain_7b_3000_pre_10']-cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_7b_3000_pre_10']+cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    plt.plot(cache['mean_mix_7b_pre_10'], label='Mix data w/o pretrain')\n",
    "    plt.fill_between(cache['x'], cache['mean_mix_7b_pre_10']-cache['std_mix_7b_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_mix_7b_pre_10']+cache['std_mix_7b_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "\n",
    "    plt.title(f'{hyperparams[\"env\"].split(\"-\")[0]} episode reward with std error for {hyperparams[\"n_exp\"]} seeds.')\n",
    "    plt.xlabel('# of episodes')\n",
    "    plt.ylabel('Episode reward')\n",
    "    if \"Cliff\" in hyperparams[\"env\"]:\n",
    "        plt.ylim(-500, 0)\n",
    "    if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "        plt.ylim(-250, -100)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_mix.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_sft_lcot(hyperparams, cache):\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(cache['mean_onl'], label='On-policy')\n",
    "        plt.fill_between(cache['x'], cache['mean_onl']-cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_onl']+cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "        plt.plot(cache['mean_pretrain_7b_3000_pre_10'], label='LORO')\n",
    "        plt.fill_between(cache['x'], cache['mean_pretrain_7b_3000_pre_10']-cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_7b_3000_pre_10']+cache['std_pretrain_7b_3000_pre_10']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "        plt.plot(cache['mean_pretrain_7b_3000_pre_10SFT'], label='SFT')\n",
    "        plt.fill_between(cache['x'], cache['mean_pretrain_7b_3000_pre_10SFT']-cache['std_pretrain_7b_3000_pre_10SFT']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_7b_3000_pre_10SFT']+cache['std_pretrain_7b_3000_pre_10SFT']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "\n",
    "        plt.title(f'{hyperparams[\"env\"].split(\"-\")[0]} episode reward with std error for {hyperparams[\"n_exp\"]} seeds.')\n",
    "        plt.xlabel('# of episodes')\n",
    "        plt.ylabel('Episode reward')\n",
    "        if \"Cliff\" in hyperparams[\"env\"]:\n",
    "            plt.ylim(-500, 0)\n",
    "        if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "            plt.ylim(-250, -100)\n",
    "        plt.legend(loc='lower right')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        plt.plot(cache['mean_pretrain_7b_3000_pre_10DS'], label='Long-CoT 7B')\n",
    "        plt.fill_between(cache['x'], cache['mean_pretrain_7b_3000_pre_10DS']-cache['std_pretrain_7b_3000_pre_10DS']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_7b_3000_pre_10DS']+cache['std_pretrain_7b_3000_pre_10DS']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "        plt.plot(cache['mean_pretrain_14b_3000_pre_10DS'], label='Long-CoT 14B')\n",
    "        plt.fill_between(cache['x'], cache['mean_pretrain_14b_3000_pre_10DS']-cache['std_pretrain_14b_3000_pre_10DS']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_pretrain_14b_3000_pre_10DS']+cache['std_pretrain_14b_3000_pre_10DS']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_sft_lcot.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_size(hyperparams, cache):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    for j in range(2):\n",
    "        if j == 0:\n",
    "            pretrain_step = 1000\n",
    "        else:\n",
    "            pretrain_step = 3000\n",
    "        for i in range(3):\n",
    "            mean_onl = cache[f'mean_onl']\n",
    "            std_onl = cache[f'std_onl']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro7 = cache[f'mean_pretrain_7b_{pretrain_step}_pre_{i+1}0']\n",
    "            std_loro7 = cache[f'std_pretrain_7b_{pretrain_step}_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro32 = cache[f'mean_pretrain_32b_{pretrain_step}_pre_{i+1}0']\n",
    "            std_loro32 = cache[f'std_pretrain_32b_{pretrain_step}_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            axs[j,i].plot(mean_onl, label='On-policy')\n",
    "            axs[j,i].fill_between(cache['x'], mean_onl-std_onl, mean_onl+std_onl, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro7, label='LORO 7B')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro7-std_loro7, mean_loro7+std_loro7, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro32, label='LORO 32B')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro32-std_loro32, mean_loro32+std_loro32, alpha=0.3)\n",
    "\n",
    "            axs[j,i].set_title(f'Pretrain {i+1}0 episodes, for {pretrain_step} steps')\n",
    "            axs[j,i].set_xlabel('# of episodes')\n",
    "            axs[j,i].set_ylabel('Episode reward')\n",
    "            if \"Cliff\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-500, 0)\n",
    "            if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-250, -100)\n",
    "    \n",
    "    axs[0,0].legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_model_size.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_pretrain_step(hyperparams, cache):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    for j in range(2):\n",
    "        if j == 0:\n",
    "            model_size = 7\n",
    "        else:\n",
    "            model_size = 32\n",
    "        for i in range(3):\n",
    "            mean_onl = cache[f'mean_onl']\n",
    "            std_onl = cache[f'std_onl']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro_1k = cache[f'mean_pretrain_{model_size}b_1000_pre_{i+1}0']\n",
    "            std_loro_1k = cache[f'std_pretrain_{model_size}b_1000_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro_3k = cache[f'mean_pretrain_{model_size}b_3000_pre_{i+1}0']\n",
    "            std_loro_3k = cache[f'std_pretrain_{model_size}b_3000_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            axs[j,i].plot(mean_onl, label='On-policy')\n",
    "            axs[j,i].fill_between(cache['x'], mean_onl-std_onl, mean_onl+std_onl, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro_1k, label='LORO 1k pretrain steps')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro_1k-std_loro_1k, mean_loro_1k+std_loro_1k, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro_3k, label='LORO 3k pretrain steps')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro_3k-std_loro_3k, mean_loro_3k+std_loro_3k, alpha=0.3)\n",
    "\n",
    "            axs[j,i].set_title(f'Pretrain {i+1}0 episodes, {model_size}B model.')\n",
    "            axs[j,i].set_xlabel('# of episodes')\n",
    "            axs[j,i].set_ylabel('Episode reward')\n",
    "            if \"Cliff\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-500, 0)\n",
    "            if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-250, -100)\n",
    "    \n",
    "    axs[0,0].legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_pretrain_step.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_pretrain_eps(hyperparams, cache):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    for j in range(2):\n",
    "        if j == 0:\n",
    "            model_size = 7\n",
    "        else:\n",
    "            model_size = 32\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                pretrain_step = 1000\n",
    "            else:\n",
    "                pretrain_step = 3000\n",
    "            mean_onl = cache[f'mean_onl']\n",
    "            std_onl = cache[f'std_onl']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro_10 = cache[f'mean_pretrain_{model_size}b_{pretrain_step}_pre_10']\n",
    "            std_loro_10 = cache[f'std_pretrain_{model_size}b_{pretrain_step}_pre_10']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro_20 = cache[f'mean_pretrain_{model_size}b_{pretrain_step}_pre_20']\n",
    "            std_loro_20 = cache[f'std_pretrain_{model_size}b_{pretrain_step}_pre_20']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_loro_30 = cache[f'mean_pretrain_{model_size}b_{pretrain_step}_pre_30']\n",
    "            std_loro_30 = cache[f'std_pretrain_{model_size}b_{pretrain_step}_pre_30']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            axs[j,i].plot(mean_onl, label='On-policy')\n",
    "            axs[j,i].fill_between(cache['x'], mean_onl-std_onl, mean_onl+std_onl, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro_10, label='LORO 10 pretrain eps')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro_10-std_loro_10, mean_loro_10+std_loro_10, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro_20, label='LORO 20 pretrain eps')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro_20-std_loro_20, mean_loro_20+std_loro_20, alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro_30, label='LORO 30 pretrain eps')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro_30-std_loro_30, mean_loro_30+std_loro_30, alpha=0.3)\n",
    "\n",
    "            axs[j,i].set_title(f'Pretrain {pretrain_step} steps, {model_size}B model.')\n",
    "            axs[j,i].set_xlabel('# of episodes')\n",
    "            axs[j,i].set_ylabel('Episode reward')\n",
    "            if \"Cliff\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-500, 0)\n",
    "            if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-250, -100)\n",
    "    \n",
    "    axs[0,0].legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_pretrain_eps.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_pretrain_big(hyperparams, cache):\n",
    "    fig, axs = plt.subplots(4, 3, figsize=(16, 20))\n",
    "    for j in range(4):\n",
    "        if j<2:\n",
    "            model_size = 7\n",
    "        else:\n",
    "            model_size = 32\n",
    "        if j%2 == 0:\n",
    "            pretrain_step = 1000\n",
    "        else:\n",
    "            pretrain_step = 3000\n",
    "        for i in range(3):\n",
    "            mean_loro = cache[f'mean_pretrain_{model_size}b_{pretrain_step}_pre_{i+1}0']\n",
    "            std_loro = cache[f'std_pretrain_{model_size}b_{pretrain_step}_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_on_pol = cache[f'mean_on_pol_pretrain_{pretrain_step}_pre_{i+1}0']\n",
    "            std_on_pol = cache[f'std_on_pol_pretrain_{pretrain_step}_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            mean_rand = cache[f'mean_rand_pretrain_{pretrain_step}_pre_{i+1}0']\n",
    "            std_rand = cache[f'std_rand_pretrain_{pretrain_step}_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "            axs[j,i].plot(cache['mean_onl'], label='On-policy')\n",
    "            axs[j,i].fill_between(cache['x'], cache['mean_onl']-cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_onl']+cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "            axs[j,i].plot(mean_loro, label='LORO')\n",
    "            axs[j,i].fill_between(cache['x'], mean_loro-std_loro, mean_loro+std_loro, alpha=0.3)\n",
    "            axs[j,i].plot(mean_on_pol, label='Pretrain w/ On-policy data')\n",
    "            axs[j,i].fill_between(cache['x'], mean_on_pol-std_on_pol, mean_on_pol+std_on_pol, alpha=0.3)\n",
    "            axs[j,i].plot(mean_rand, label='Pretrain w/ random policy data')\n",
    "            axs[j,i].fill_between(cache['x'], mean_rand-std_rand, mean_rand+std_rand, alpha=0.3)\n",
    "\n",
    "            axs[j,i].set_title(f'Pretrain {i+1}0 episodes, {model_size}B model, for {pretrain_step} steps')\n",
    "            axs[j,i].set_xlabel('# of episodes')\n",
    "            axs[j,i].set_ylabel('Episode reward')\n",
    "            if \"Cliff\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-500, 0)\n",
    "            if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "                axs[j,i].set_ylim(-250, -100)\n",
    "    \n",
    "    axs[0,0].legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_pretrain_big.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_sft_lcot_big(hyperparams, cache):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    for j in range(2):\n",
    "        if j == 0:\n",
    "            pretrain_step = 1000\n",
    "        else:\n",
    "            pretrain_step = 3000\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                mean_loro = cache[f'mean_pretrain_7b_{pretrain_step}_pre_{i+1}0']\n",
    "                std_loro = cache[f'std_pretrain_7b_{pretrain_step}_pre_{i+1}0']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "                mean_sft = cache[f'mean_pretrain_7b_{pretrain_step}_pre_{i+1}0SFT']\n",
    "                std_sft = cache[f'mean_pretrain_7b_{pretrain_step}_pre_{i+1}0SFT']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "                axs[j,i].plot(cache['mean_onl'], label='On-policy')\n",
    "                axs[j,i].fill_between(cache['x'], cache['mean_onl']-cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), cache['mean_onl']+cache['std_onl']/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.3)\n",
    "                axs[j,i].plot(mean_loro, label='LORO')\n",
    "                axs[j,i].fill_between(cache['x'], mean_loro-std_loro, mean_loro+std_loro, alpha=0.3)\n",
    "                axs[j,i].plot(mean_sft, label='SFT')\n",
    "                axs[j,i].fill_between(cache['x'], mean_sft-std_sft, mean_sft+std_sft, alpha=0.3)\n",
    "\n",
    "                axs[j,i].set_title(f'Pretrain {i+1}0 episodes, 7B model, for {pretrain_step} steps')\n",
    "                axs[j,i].set_xlabel('# of episodes')\n",
    "                axs[j,i].set_ylabel('Episode reward')\n",
    "                if \"Cliff\" in hyperparams[\"env\"]:\n",
    "                    axs[j,i].set_ylim(-500, 0)\n",
    "                if \"MountainCar\" in hyperparams[\"env\"]:\n",
    "                    axs[j,i].set_ylim(-250, -100)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                mean_ds7 = cache[f'mean_pretrain_7b_{pretrain_step}_pre_{i+1}0DS']\n",
    "                std_ds7 = cache[f'mean_pretrain_7b_{pretrain_step}_pre_{i+1}0DS']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "                mean_ds14 = cache[f'mean_pretrain_14b_{pretrain_step}_pre_{i+1}0DS']\n",
    "                std_ds14 = cache[f'mean_pretrain_14b_{pretrain_step}_pre_{i+1}0DS']/np.sqrt(hyperparams[\"n_exp\"])\n",
    "                axs[j,i].plot(mean_ds7, label='Long-CoT 7B')\n",
    "                axs[j,i].fill_between(cache['x'], mean_ds7-std_ds7, mean_ds7+std_ds7, alpha=0.3)\n",
    "                axs[j,i].plot(mean_ds14, label='Long-CoT 14B')\n",
    "                axs[j,i].fill_between(cache['x'], mean_ds14-std_ds14, mean_ds14+std_ds14, alpha=0.3)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    axs[0,0].legend(loc='lower right')\n",
    "    plt.savefig(f'figs/{hyperparams[\"env\"].split(\"-\")[0]}_sft_lcot_bigs.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7a300edb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/cache_RepresentedPong_on_policy_pretrain_exp_rand.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_cache \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQwen_7B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQwen_32B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDS_7B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDS_14B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQwen_7B_SFT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plot_main(hyperparams, all_cache)\n\u001b[1;32m      3\u001b[0m plot_pretrain(hyperparams, all_cache)\n",
      "Cell \u001b[0;32mIn[187], line 10\u001b[0m, in \u001b[0;36mextract_data\u001b[0;34m(hyperparams, Qwen_7B, Qwen_32B, DS_7B, DS_14B, Qwen_7B_SFT)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/cache_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhyperparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_on_policy_pretrain_exp.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      9\u001b[0m     on_policy_pretrain_cache \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/cache_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_on_policy_pretrain_exp_rand.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     11\u001b[0m     rand_pretrain_cache \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llamagym/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/cache_RepresentedPong_on_policy_pretrain_exp_rand.pkl'"
     ]
    }
   ],
   "source": [
    "all_cache = extract_data(hyperparams, Qwen_7B, Qwen_32B, DS_7B, DS_14B, Qwen_7B_SFT)\n",
    "plot_main(hyperparams, all_cache)\n",
    "plot_pretrain(hyperparams, all_cache)\n",
    "# plot_pretrain_big(hyperparams, all_cache)\n",
    "plot_mix(hyperparams, all_cache)\n",
    "plot_model_size(hyperparams, all_cache)\n",
    "plot_pretrain_step(hyperparams, all_cache)\n",
    "plot_pretrain_eps(hyperparams, all_cache)\n",
    "# plot_sft_lcot(hyperparams, all_cache)\n",
    "plot_sft_lcot_big(hyperparams, all_cache)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamagym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
