{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6d073-1157-4f34-8628-d1474ef97d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:04.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRegister Shimmy environments. \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thangduong/miniconda3/envs/llamagym/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import d3rlpy\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from env.atari.represented_atari_game import GymCompatWrapper2\n",
    "from online_main import OneHotWrapper\n",
    "\n",
    "hyperparams = {\n",
    "        \"env\": \"FrozenLake-v1\", #\"CartPole-v0\", # \"Acrobot-v0\", \"MountainCar-v0\", \"FrozenLake-v1\", \"CliffWalking-v0\", \"Taxi-v3\", \"RepresentedPong-v0\"\n",
    "        \"seed\": 42069,\n",
    "        \"n_episodes\": 100,#5000,\n",
    "        \"max_episode_len\": 200, # Around 10h per 100k steps in Leviathan server\n",
    "        \"eps\": 0.1,  # epsilon for exploration\n",
    "        \"n_exp\": 5,\n",
    "        \"n_pretrain_eps\": 30,\n",
    "        \"n_online_eps\": 170, #10-290 for mountainCar, 30-170 for CartPole\n",
    "        \"gpu\": True, # True if use GPU to train with d3rlpy\n",
    "        \"buffer_size\": 100000, #Test with 100k, 200k, 500k. 1M might be too much\n",
    "        \"data_path\": None,#'data/CartPole_Qwen2.5-7B-Instruct_Neps_10_20250406040150.pkl',\n",
    "        \"model_path\": None,#'d3rlpy_loss/DoubleDQN_online_20250331153346/model_600000.d3',\n",
    "        \"batch_size\":256, #Test smaller batch size: 32, 64. May be noisier\n",
    "        \"learning_rate\":5e-5,\n",
    "        \"gamma\":0.99,\n",
    "        \"target_update_interval\":1000 #Test with 1k, 2k, 5k\n",
    "    }\n",
    "\n",
    "if \"Represented\" in hyperparams[\"env\"]:\n",
    "    env = GymCompatWrapper2(gym.make(hyperparams[\"env\"]))\n",
    "    eval_env = GymCompatWrapper2(gym.make(hyperparams[\"env\"]))\n",
    "elif isinstance(gym.make(hyperparams[\"env\"]).observation_space, gym.spaces.Discrete):\n",
    "    env = OneHotWrapper(gym.make(hyperparams[\"env\"]))\n",
    "    eval_env = OneHotWrapper(gym.make(hyperparams[\"env\"]))\n",
    "else:\n",
    "    env = gym.make(hyperparams[\"env\"])\n",
    "    eval_env = gym.make(hyperparams[\"env\"])\n",
    "\n",
    "# fix seed\n",
    "d3rlpy.seed(hyperparams[\"seed\"])\n",
    "d3rlpy.envs.seed_env(env, hyperparams[\"seed\"])\n",
    "d3rlpy.envs.seed_env(eval_env, hyperparams[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e63425",
   "metadata": {},
   "source": [
    "### Test online training a new env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6fd1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0.0, 1.0, (48,), float32)\n",
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int64')], shape=[()])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(48,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[[1]])\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m4\u001b[0m\n",
      "Empty buffer (just Online training)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181231\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding model...             \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModel has been built.         \u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 619.83it/s]\n",
      "  0%|          | 1/300 [00:01<06:20,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181232\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.32\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 219.72it/s]\n",
      "  1%|          | 2/300 [00:03<08:21,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181234\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 154.29it/s]\n",
      "  1%|          | 3/300 [00:05<09:45,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181237\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.79it/s]\n",
      "  1%|▏         | 4/300 [00:07<10:34,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181239\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.39\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 152.20it/s]\n",
      "  2%|▏         | 5/300 [00:10<10:55,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181241\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.41\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 158.06it/s]\n",
      "  2%|▏         | 6/300 [00:12<10:55,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181244\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.44\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 156.76it/s]\n",
      "  2%|▏         | 7/300 [00:14<11:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181246\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.73it/s]\n",
      "  3%|▎         | 8/300 [00:17<11:14,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181248\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.48\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.00it/s]\n",
      "  3%|▎         | 9/300 [00:19<11:22,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181251\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.41it/s]\n",
      "  3%|▎         | 10/300 [00:22<11:28,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181253\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.14it/s]\n",
      "  4%|▎         | 11/300 [00:24<11:26,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181256\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.56\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 153.37it/s]\n",
      "  4%|▍         | 12/300 [00:26<11:23,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:12.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181258\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.58\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:12.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.34it/s]\n",
      "  4%|▍         | 13/300 [00:29<11:23,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181300\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.00\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.88it/s]\n",
      "  5%|▍         | 14/300 [00:31<11:18,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181303\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.03\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 153.05it/s]\n",
      "  5%|▌         | 15/300 [00:34<11:16,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181305\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.05\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.58it/s]\n",
      "  5%|▌         | 16/300 [00:36<11:11,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181308\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.08\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.31it/s]\n",
      "  6%|▌         | 17/300 [00:38<11:12,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181310\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.10\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.67it/s]\n",
      "  6%|▌         | 18/300 [00:41<11:10,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181312\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.12\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.33it/s]\n",
      "  6%|▋         | 19/300 [00:43<11:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181315\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.15\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.25it/s]\n",
      "  7%|▋         | 20/300 [00:46<11:11,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181317\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.17\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.61it/s]\n",
      "  7%|▋         | 21/300 [00:48<11:07,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181320\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.20\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.55it/s]\n",
      "  7%|▋         | 22/300 [00:50<11:07,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181322\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.22\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.74it/s]\n",
      "  8%|▊         | 23/300 [00:53<11:01,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181324\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.24\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.34it/s]\n",
      "  8%|▊         | 24/300 [00:55<10:59,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181327\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 152.08it/s]\n",
      "  8%|▊         | 25/300 [00:57<10:52,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181329\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.29\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.86it/s]\n",
      "  9%|▊         | 26/300 [01:00<10:53,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181331\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.31\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.28it/s]\n",
      "  9%|▉         | 27/300 [01:02<10:55,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181334\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.84it/s]\n",
      "  9%|▉         | 28/300 [01:05<10:55,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181336\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.36\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.71it/s]\n",
      " 10%|▉         | 29/300 [01:07<10:55,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181339\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.39\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.69it/s]\n",
      " 10%|█         | 30/300 [01:10<10:54,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181341\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.41\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.81it/s]\n",
      " 10%|█         | 31/300 [01:12<10:51,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181344\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.44\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.23it/s]\n",
      " 11%|█         | 32/300 [01:15<10:56,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181346\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 129.56it/s]\n",
      " 11%|█         | 33/300 [01:17<11:06,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181349\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.49\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.85it/s]\n",
      " 11%|█▏        | 34/300 [01:20<11:07,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181351\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 139.42it/s]\n",
      " 12%|█▏        | 35/300 [01:22<11:02,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181354\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.90it/s]\n",
      " 12%|█▏        | 36/300 [01:25<10:56,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181356\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.56\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.64it/s]\n",
      " 12%|█▏        | 37/300 [01:27<10:44,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:13.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181359\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:13.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.28it/s]\n",
      " 13%|█▎        | 38/300 [01:29<10:37,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181401\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.01\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.89it/s]\n",
      " 13%|█▎        | 39/300 [01:32<10:28,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181403\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.03\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.76it/s]\n",
      " 13%|█▎        | 40/300 [01:34<10:30,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181406\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.06\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.11it/s]\n",
      " 14%|█▎        | 41/300 [01:37<10:27,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181408\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.08\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.15it/s]\n",
      " 14%|█▍        | 42/300 [01:39<10:29,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181411\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.11\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.03it/s]\n",
      " 14%|█▍        | 43/300 [01:41<10:26,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181413\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.79it/s]\n",
      " 15%|█▍        | 44/300 [01:44<10:22,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181416\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.35it/s]\n",
      " 15%|█▌        | 45/300 [01:46<10:24,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181418\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.99it/s]\n",
      " 15%|█▌        | 46/300 [01:49<10:19,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181420\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.20\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.67it/s]\n",
      " 16%|█▌        | 47/300 [01:51<10:16,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181423\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.45it/s]\n",
      " 16%|█▌        | 48/300 [01:54<10:09,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181425\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.25\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.61it/s]\n",
      " 16%|█▋        | 49/300 [01:56<10:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181428\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.28\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.72it/s]\n",
      " 17%|█▋        | 50/300 [01:58<09:58,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181430\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.30\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.76it/s]\n",
      " 17%|█▋        | 51/300 [02:01<10:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181432\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.32\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.94it/s]\n",
      " 17%|█▋        | 52/300 [02:03<09:58,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181435\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.35\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.40it/s]\n",
      " 18%|█▊        | 53/300 [02:06<09:52,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181437\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.92it/s]\n",
      " 18%|█▊        | 54/300 [02:08<09:50,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181440\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.40\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.40it/s]\n",
      " 18%|█▊        | 55/300 [02:10<09:54,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181442\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.42\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.73it/s]\n",
      " 19%|█▊        | 56/300 [02:13<09:52,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181445\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.45\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.87it/s]\n",
      " 19%|█▉        | 57/300 [02:15<09:48,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181447\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.47\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.80it/s]\n",
      " 19%|█▉        | 58/300 [02:18<09:41,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181449\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.49\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.99it/s]\n",
      " 20%|█▉        | 59/300 [02:20<09:46,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181452\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.52\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.54it/s]\n",
      " 20%|██        | 60/300 [02:23<09:45,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181454\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.48it/s]\n",
      " 20%|██        | 61/300 [02:25<09:37,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181457\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.57\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 138.76it/s]\n",
      " 21%|██        | 62/300 [02:27<09:31,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:14.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181459\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:14.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.02it/s]\n",
      " 21%|██        | 63/300 [02:30<09:26,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181501\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.01\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.54it/s]\n",
      " 21%|██▏       | 64/300 [02:32<09:28,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181504\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.61it/s]\n",
      " 22%|██▏       | 65/300 [02:35<09:31,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181506\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.06\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.80it/s]\n",
      " 22%|██▏       | 66/300 [02:37<09:26,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181509\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.09\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.71it/s]\n",
      " 22%|██▏       | 67/300 [02:39<09:19,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181511\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.11\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 155.91it/s]\n",
      " 23%|██▎       | 68/300 [02:42<09:12,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181513\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 139.16it/s]\n",
      " 23%|██▎       | 69/300 [02:44<09:19,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181516\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 167.50it/s]\n",
      " 23%|██▎       | 70/300 [02:47<09:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181518\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 112.43it/s]\n",
      " 24%|██▎       | 71/300 [02:49<09:27,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181521\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.78it/s]\n",
      " 24%|██▍       | 72/300 [02:52<09:26,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181523\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.02it/s]\n",
      " 24%|██▍       | 73/300 [02:54<09:29,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181526\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.26\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 128.40it/s]\n",
      " 25%|██▍       | 74/300 [02:57<09:38,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181529\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.29\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.55it/s]\n",
      " 25%|██▌       | 75/300 [03:00<09:36,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181531\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.31\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.55it/s]\n",
      " 25%|██▌       | 76/300 [03:02<09:26,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181534\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.32it/s]\n",
      " 26%|██▌       | 77/300 [03:04<09:16,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181536\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.36\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.76it/s]\n",
      " 26%|██▌       | 78/300 [03:07<09:06,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181538\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.38\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.31it/s]\n",
      " 26%|██▋       | 79/300 [03:09<09:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181541\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.41\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.56it/s]\n",
      " 27%|██▋       | 80/300 [03:12<08:55,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181543\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.43\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.47it/s]\n",
      " 27%|██▋       | 81/300 [03:14<08:51,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181546\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 128.84it/s]\n",
      " 27%|██▋       | 82/300 [03:17<09:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181548\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.48\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.26it/s]\n",
      " 28%|██▊       | 83/300 [03:19<08:53,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181551\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.92it/s]\n",
      " 28%|██▊       | 84/300 [03:21<08:48,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181553\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.01it/s]\n",
      " 28%|██▊       | 85/300 [03:24<08:40,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181555\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.55\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.45it/s]\n",
      " 29%|██▊       | 86/300 [03:26<08:37,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:15.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181558\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.58\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:15.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.96it/s]\n",
      " 29%|██▉       | 87/300 [03:29<08:36,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181600\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.00\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.71it/s]\n",
      " 29%|██▉       | 88/300 [03:31<08:34,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181603\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.03\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 152.40it/s]\n",
      " 30%|██▉       | 89/300 [03:34<08:30,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181605\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.05\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.32it/s]\n",
      " 30%|███       | 90/300 [03:36<08:30,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181608\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.08\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.60it/s]\n",
      " 30%|███       | 91/300 [03:38<08:29,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181610\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.10\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.68it/s]\n",
      " 31%|███       | 92/300 [03:41<08:27,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181613\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.60it/s]\n",
      " 31%|███       | 93/300 [03:43<08:25,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181615\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.15\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.85it/s]\n",
      " 31%|███▏      | 94/300 [03:46<08:17,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181617\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.17\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.87it/s]\n",
      " 32%|███▏      | 95/300 [03:48<08:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181620\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.20\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.11it/s]\n",
      " 32%|███▏      | 96/300 [03:51<08:13,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181622\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.22\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.26it/s]\n",
      " 32%|███▏      | 97/300 [03:53<08:13,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181625\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.25\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.19it/s]\n",
      " 33%|███▎      | 98/300 [03:55<08:11,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181627\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.91it/s]\n",
      " 33%|███▎      | 99/300 [03:58<08:09,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181630\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.30\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 140.23it/s]\n",
      " 33%|███▎      | 100/300 [04:00<08:06,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181632\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.32\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.57it/s]\n",
      " 34%|███▎      | 101/300 [04:03<08:04,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181634\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.74it/s]\n",
      " 34%|███▍      | 102/300 [04:05<08:04,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181637\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.43it/s]\n",
      " 34%|███▍      | 103/300 [04:08<07:59,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181639\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.39\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.74it/s]\n",
      " 35%|███▍      | 104/300 [04:10<07:55,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181642\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.42\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.64it/s]\n",
      " 35%|███▌      | 105/300 [04:12<07:52,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181644\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.44\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.07it/s]\n",
      " 35%|███▌      | 106/300 [04:15<07:54,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181647\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.47\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.14it/s]\n",
      " 36%|███▌      | 107/300 [04:17<07:49,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181649\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.49\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.26it/s]\n",
      " 36%|███▌      | 108/300 [04:20<07:47,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181651\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.53it/s]\n",
      " 36%|███▋      | 109/300 [04:22<07:46,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181654\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.20it/s]\n",
      " 37%|███▋      | 110/300 [04:25<07:43,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181656\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.56\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.96it/s]\n",
      " 37%|███▋      | 111/300 [04:27<07:43,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:16.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181659\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:16.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.08it/s]\n",
      " 37%|███▋      | 112/300 [04:30<07:41,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181701\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.01\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.26it/s]\n",
      " 38%|███▊      | 113/300 [04:32<07:41,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181704\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.82it/s]\n",
      " 38%|███▊      | 114/300 [04:35<07:37,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181706\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.06\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 147.48it/s]\n",
      " 38%|███▊      | 115/300 [04:37<07:35,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181709\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.09\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.65it/s]\n",
      " 39%|███▊      | 116/300 [04:39<07:32,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181711\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.11\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.57it/s]\n",
      " 39%|███▉      | 117/300 [04:42<07:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181714\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.14\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.34it/s]\n",
      " 39%|███▉      | 118/300 [04:44<07:27,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181716\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.79it/s]\n",
      " 40%|███▉      | 119/300 [04:47<07:21,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181718\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.85it/s]\n",
      " 40%|████      | 120/300 [04:49<07:21,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181721\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.83it/s]\n",
      " 40%|████      | 121/300 [04:52<07:20,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181723\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 148.06it/s]\n",
      " 41%|████      | 122/300 [04:54<07:19,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181726\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.26\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.23it/s]\n",
      " 41%|████      | 123/300 [04:57<07:14,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181728\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.28\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.31it/s]\n",
      " 41%|████▏     | 124/300 [04:59<07:14,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181731\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.31\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.61it/s]\n",
      " 42%|████▏     | 125/300 [05:02<07:07,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181733\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.33\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.94it/s]\n",
      " 42%|████▏     | 126/300 [05:04<07:06,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181736\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.36\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.40it/s]\n",
      " 42%|████▏     | 127/300 [05:05<06:12,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181737\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 150.25it/s]\n",
      " 43%|████▎     | 128/300 [05:07<05:32,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181739\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.39\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.42it/s]\n",
      " 43%|████▎     | 129/300 [05:08<05:07,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181740\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.40\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 139.84it/s]\n",
      " 43%|████▎     | 130/300 [05:10<04:51,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181742\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.42\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 140.13it/s]\n",
      " 44%|████▎     | 131/300 [05:11<04:39,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181743\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.43\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.43it/s]\n",
      " 44%|████▍     | 132/300 [05:14<05:18,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181746\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.67it/s]\n",
      " 44%|████▍     | 133/300 [05:15<04:56,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181747\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.47\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 140.60it/s]\n",
      " 45%|████▍     | 134/300 [05:17<04:40,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181748\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.48\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.10it/s]\n",
      " 45%|████▌     | 135/300 [05:19<05:14,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181751\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.18it/s]\n",
      " 45%|████▌     | 136/300 [05:22<05:41,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181753\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 129.03it/s]\n",
      " 46%|████▌     | 137/300 [05:24<06:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181756\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.56\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 113.54it/s]\n",
      " 46%|████▌     | 138/300 [05:27<06:37,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:17.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181759\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:17.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 128.90it/s]\n",
      " 46%|████▋     | 139/300 [05:30<06:42,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181802\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.02\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 118.68it/s]\n",
      " 47%|████▋     | 140/300 [05:33<06:52,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181804\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 105.26it/s]\n",
      " 47%|████▋     | 141/300 [05:36<07:15,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181807\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.07\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 105.61it/s]\n",
      " 47%|████▋     | 142/300 [05:39<07:29,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181811\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.11\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 107.18it/s]\n",
      " 48%|████▊     | 143/300 [05:41<06:45,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181812\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.12\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 91.42it/s]\n",
      " 48%|████▊     | 144/300 [05:43<06:29,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181815\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.15\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 112.53it/s]\n",
      " 48%|████▊     | 145/300 [05:46<06:57,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181818\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 102.87it/s]\n",
      " 49%|████▊     | 146/300 [05:49<07:11,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181821\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 101.73it/s]\n",
      " 49%|████▉     | 147/300 [05:51<06:34,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181823\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 97.88it/s] \n",
      " 49%|████▉     | 148/300 [05:54<06:13,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181825\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.25\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 95.66it/s] \n",
      " 50%|████▉     | 149/300 [05:56<05:58,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181827\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 113.30it/s]\n",
      " 50%|█████     | 150/300 [05:59<06:17,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181830\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.30\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 110.38it/s]\n",
      " 50%|█████     | 151/300 [06:01<05:47,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181832\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.32\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 109.82it/s]\n",
      " 51%|█████     | 152/300 [06:04<06:19,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181835\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.35\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 105.00it/s]\n",
      " 51%|█████     | 153/300 [06:06<05:52,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181837\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 100.88it/s]\n",
      " 51%|█████▏    | 154/300 [06:08<05:36,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181839\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.39\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 118.65it/s]\n",
      " 52%|█████▏    | 155/300 [06:10<05:11,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181841\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.41\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 107.91it/s]\n",
      " 52%|█████▏    | 156/300 [06:12<05:44,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181844\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.44\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.03it/s]\n",
      " 52%|█████▏    | 157/300 [06:14<05:08,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181846\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 127.62it/s]\n",
      " 53%|█████▎    | 158/300 [06:16<04:44,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181847\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.47\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.27it/s]\n",
      " 53%|█████▎    | 159/300 [06:17<04:19,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181849\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.49\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 121.79it/s]\n",
      " 53%|█████▎    | 160/300 [06:19<04:13,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181851\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 127.73it/s]\n",
      " 54%|█████▎    | 161/300 [06:21<04:04,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181852\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.52\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 145.63it/s]\n",
      " 54%|█████▍    | 162/300 [06:22<03:50,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181854\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 120.05it/s]\n",
      " 54%|█████▍    | 163/300 [06:24<03:51,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181855\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.55\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 124.82it/s]\n",
      " 55%|█████▍    | 164/300 [06:25<03:49,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181857\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.57\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 149.71it/s]\n",
      " 55%|█████▌    | 165/300 [06:27<03:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:18.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181858\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.58\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:18.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.46it/s]\n",
      " 55%|█████▌    | 166/300 [06:28<03:29,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181900\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.00\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 155.59it/s]\n",
      " 56%|█████▌    | 167/300 [06:30<03:20,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181901\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.01\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.48it/s]\n",
      " 56%|█████▌    | 168/300 [06:31<03:19,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181903\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.03\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 144.42it/s]\n",
      " 56%|█████▋    | 169/300 [06:33<03:15,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181904\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.20it/s]\n",
      " 57%|█████▋    | 170/300 [06:34<03:13,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181906\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.06\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 142.37it/s]\n",
      " 57%|█████▋    | 171/300 [06:36<03:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181907\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.07\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.04it/s]\n",
      " 57%|█████▋    | 172/300 [06:37<03:14,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181909\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.09\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.80it/s]\n",
      " 58%|█████▊    | 173/300 [06:39<03:16,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181910\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.10\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.64it/s]\n",
      " 58%|█████▊    | 174/300 [06:41<03:51,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181913\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.48it/s]\n",
      " 58%|█████▊    | 175/300 [06:43<03:36,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181914\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.14\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 140.99it/s]\n",
      " 59%|█████▊    | 176/300 [06:44<03:26,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181916\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 141.91it/s]\n",
      " 59%|█████▉    | 177/300 [06:46<03:18,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181917\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.17\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.49it/s]\n",
      " 59%|█████▉    | 178/300 [06:47<03:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181919\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.19\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 139.82it/s]\n",
      " 60%|█████▉    | 179/300 [06:49<03:10,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181921\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 139.54it/s]\n",
      " 60%|██████    | 180/300 [06:50<03:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181922\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.22\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.03it/s]\n",
      " 60%|██████    | 181/300 [06:52<03:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181924\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.24\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.88it/s]\n",
      " 61%|██████    | 182/300 [06:54<03:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181925\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.25\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.23it/s]\n",
      " 61%|██████    | 183/300 [06:55<03:02,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181927\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 138.67it/s]\n",
      " 61%|██████▏   | 184/300 [06:57<02:59,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181928\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.28\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.82it/s]\n",
      " 62%|██████▏   | 185/300 [06:58<02:58,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181930\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.30\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.81it/s]\n",
      " 62%|██████▏   | 186/300 [07:00<02:55,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181931\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.31\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.13it/s]\n",
      " 62%|██████▏   | 187/300 [07:01<02:54,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181933\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.33\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.58it/s]\n",
      " 63%|██████▎   | 188/300 [07:03<02:52,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181934\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.77it/s]\n",
      " 63%|██████▎   | 189/300 [07:04<02:50,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181936\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.36\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.60it/s]\n",
      " 63%|██████▎   | 190/300 [07:06<02:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181937\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.06it/s]\n",
      " 64%|██████▎   | 191/300 [07:07<02:48,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181939\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.39\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 138.73it/s]\n",
      " 64%|██████▍   | 192/300 [07:09<02:45,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181941\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.41\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.85it/s]\n",
      " 64%|██████▍   | 193/300 [07:10<02:43,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181942\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.42\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.92it/s]\n",
      " 65%|██████▍   | 194/300 [07:12<02:42,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181944\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.44\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.59it/s]\n",
      " 65%|██████▌   | 195/300 [07:14<02:41,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181945\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.45\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.56it/s]\n",
      " 65%|██████▌   | 196/300 [07:15<02:40,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181947\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.47\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.78it/s]\n",
      " 66%|██████▌   | 197/300 [07:17<02:38,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181948\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.48\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.07it/s]\n",
      " 66%|██████▌   | 198/300 [07:18<02:37,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181950\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.50\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.61it/s]\n",
      " 66%|██████▋   | 199/300 [07:20<02:35,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181951\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.02it/s]\n",
      " 67%|██████▋   | 200/300 [07:21<02:34,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181953\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.15it/s]\n",
      " 67%|██████▋   | 201/300 [07:23<02:32,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181954\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.07it/s]\n",
      " 67%|██████▋   | 202/300 [07:25<02:59,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181957\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.57\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 139.53it/s]\n",
      " 68%|██████▊   | 203/300 [07:28<03:15,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:19.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415181959\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:19.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 143.04it/s]\n",
      " 68%|██████▊   | 204/300 [07:29<02:57,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182001\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.01\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.49it/s]\n",
      " 68%|██████▊   | 205/300 [07:31<02:46,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182002\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.02\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.23it/s]\n",
      " 69%|██████▊   | 206/300 [07:32<02:39,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182004\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.74it/s]\n",
      " 69%|██████▉   | 207/300 [07:34<02:33,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182005\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.05\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.69it/s]\n",
      " 69%|██████▉   | 208/300 [07:35<02:28,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182007\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.07\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.41it/s]\n",
      " 70%|██████▉   | 209/300 [07:37<02:25,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182009\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.09\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.69it/s]\n",
      " 70%|███████   | 210/300 [07:38<02:22,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182010\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.10\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.07it/s]\n",
      " 70%|███████   | 211/300 [07:40<02:19,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182012\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.12\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.93it/s]\n",
      " 71%|███████   | 212/300 [07:42<02:18,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182013\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.09it/s]\n",
      " 71%|███████   | 213/300 [07:43<02:16,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182015\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.15\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.03it/s]\n",
      " 71%|███████▏  | 214/300 [07:45<02:14,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182016\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.83it/s]\n",
      " 72%|███████▏  | 215/300 [07:46<02:13,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182018\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.77it/s]\n",
      " 72%|███████▏  | 216/300 [07:48<02:12,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182020\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.20\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.83it/s]\n",
      " 72%|███████▏  | 217/300 [07:49<02:09,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182021\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.36it/s]\n",
      " 73%|███████▎  | 218/300 [07:51<02:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182023\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.24it/s]\n",
      " 73%|███████▎  | 219/300 [07:53<02:05,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182024\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.24\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.53it/s]\n",
      " 73%|███████▎  | 220/300 [07:54<02:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182026\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.26\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.17it/s]\n",
      " 74%|███████▎  | 221/300 [07:56<02:02,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182027\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.22it/s]\n",
      " 74%|███████▍  | 222/300 [07:57<02:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182029\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.29\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.78it/s]\n",
      " 74%|███████▍  | 223/300 [07:59<02:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182030\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.30\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 123.15it/s]\n",
      " 75%|███████▍  | 224/300 [08:00<02:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182032\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.32\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.86it/s]\n",
      " 75%|███████▌  | 225/300 [08:02<01:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182034\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.73it/s]\n",
      " 75%|███████▌  | 226/300 [08:04<01:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182035\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.35\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.44it/s]\n",
      " 76%|███████▌  | 227/300 [08:05<01:55,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182037\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.21it/s]\n",
      " 76%|███████▌  | 228/300 [08:07<01:54,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182038\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.38\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.52it/s]\n",
      " 76%|███████▋  | 229/300 [08:08<01:52,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182040\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.40\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.06it/s]\n",
      " 77%|███████▋  | 230/300 [08:10<01:51,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182042\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.42\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.19it/s]\n",
      " 77%|███████▋  | 231/300 [08:11<01:48,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182043\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.43\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.22it/s]\n",
      " 77%|███████▋  | 232/300 [08:13<01:46,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182045\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.45\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 123.98it/s]\n",
      " 78%|███████▊  | 233/300 [08:15<01:47,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182046\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.42it/s]\n",
      " 78%|███████▊  | 234/300 [08:16<01:44,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182048\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.48\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.85it/s]\n",
      " 78%|███████▊  | 235/300 [08:18<01:42,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182049\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.49\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.68it/s]\n",
      " 79%|███████▊  | 236/300 [08:19<01:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182051\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.95it/s]\n",
      " 79%|███████▉  | 237/300 [08:21<01:39,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182053\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.01it/s]\n",
      " 79%|███████▉  | 238/300 [08:23<01:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182054\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.45it/s]\n",
      " 80%|███████▉  | 239/300 [08:24<01:35,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182056\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.56\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.15it/s]\n",
      " 80%|████████  | 240/300 [08:26<01:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182057\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.57\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.00it/s]\n",
      " 80%|████████  | 241/300 [08:27<01:33,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:20.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182059\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:20.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.10it/s]\n",
      " 81%|████████  | 242/300 [08:29<01:32,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182101\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.01\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.90it/s]\n",
      " 81%|████████  | 243/300 [08:30<01:30,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182102\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.02\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.65it/s]\n",
      " 81%|████████▏ | 244/300 [08:32<01:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182104\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.62it/s]\n",
      " 82%|████████▏ | 245/300 [08:34<01:26,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182105\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.05\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.16it/s]\n",
      " 82%|████████▏ | 246/300 [08:35<01:24,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182107\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.07\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.96it/s]\n",
      " 82%|████████▏ | 247/300 [08:37<01:23,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182108\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.08\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.85it/s]\n",
      " 83%|████████▎ | 248/300 [08:38<01:21,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182110\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.10\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 137.20it/s]\n",
      " 83%|████████▎ | 249/300 [08:40<01:19,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182111\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.11\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.33it/s]\n",
      " 83%|████████▎ | 250/300 [08:41<01:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182113\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.02it/s]\n",
      " 84%|████████▎ | 251/300 [08:43<01:17,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182115\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.15\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.35it/s]\n",
      " 84%|████████▍ | 252/300 [08:45<01:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182116\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.82it/s]\n",
      " 84%|████████▍ | 253/300 [08:46<01:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182118\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.32it/s]\n",
      " 85%|████████▍ | 254/300 [08:48<01:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182119\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.19\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.20it/s]\n",
      " 85%|████████▌ | 255/300 [08:49<01:10,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182121\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.50it/s]\n",
      " 85%|████████▌ | 256/300 [08:51<01:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182123\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.00it/s]\n",
      " 86%|████████▌ | 257/300 [08:52<01:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182124\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.24\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.01it/s]\n",
      " 86%|████████▌ | 258/300 [08:54<01:06,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182126\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.26\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.42it/s]\n",
      " 86%|████████▋ | 259/300 [08:56<01:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182127\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.48it/s]\n",
      " 87%|████████▋ | 260/300 [08:57<01:02,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182129\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.29\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.39it/s]\n",
      " 87%|████████▋ | 261/300 [08:59<01:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182130\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.30\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.66it/s]\n",
      " 87%|████████▋ | 262/300 [09:00<00:59,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182132\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.32\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.63it/s]\n",
      " 88%|████████▊ | 263/300 [09:02<00:58,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182134\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.34\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.44it/s]\n",
      " 88%|████████▊ | 264/300 [09:04<00:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182135\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.35\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.80it/s]\n",
      " 88%|████████▊ | 265/300 [09:05<00:55,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182137\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.77it/s]\n",
      " 89%|████████▊ | 266/300 [09:07<00:53,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182138\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.38\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.47it/s]\n",
      " 89%|████████▉ | 267/300 [09:08<00:51,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182140\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.40\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.40\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.92it/s]\n",
      " 89%|████████▉ | 268/300 [09:10<00:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182141\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.41\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.43it/s]\n",
      " 90%|████████▉ | 269/300 [09:11<00:49,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182143\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.43\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.74it/s]\n",
      " 90%|█████████ | 270/300 [09:13<00:47,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182145\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.45\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.20it/s]\n",
      " 90%|█████████ | 271/300 [09:15<00:45,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182146\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.46\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.42it/s]\n",
      " 91%|█████████ | 272/300 [09:16<00:44,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182148\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.48\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.10it/s]\n",
      " 91%|█████████ | 273/300 [09:18<00:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182149\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.49\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.39it/s]\n",
      " 91%|█████████▏| 274/300 [09:19<00:40,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182151\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.51\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.83it/s]\n",
      " 92%|█████████▏| 275/300 [09:21<00:39,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182153\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.53\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.32it/s]\n",
      " 92%|█████████▏| 276/300 [09:22<00:37,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182154\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.54\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.60it/s]\n",
      " 92%|█████████▏| 277/300 [09:24<00:36,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182156\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.56\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.48it/s]\n",
      " 93%|█████████▎| 278/300 [09:26<00:34,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182157\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.57\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 128.95it/s]\n",
      " 93%|█████████▎| 279/300 [09:27<00:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:21.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182159\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:21.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.23it/s]\n",
      " 93%|█████████▎| 280/300 [09:29<00:31,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182200\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.00\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.63it/s]\n",
      " 94%|█████████▎| 281/300 [09:30<00:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182202\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.02\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.38it/s]\n",
      " 94%|█████████▍| 282/300 [09:32<00:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182204\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.41it/s]\n",
      " 94%|█████████▍| 283/300 [09:34<00:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182205\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.05\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 129.25it/s]\n",
      " 95%|█████████▍| 284/300 [09:35<00:25,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182207\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.07\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.43it/s]\n",
      " 95%|█████████▌| 285/300 [09:37<00:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182209\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.09\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.29it/s]\n",
      " 95%|█████████▌| 286/300 [09:38<00:22,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182210\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.10\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.62it/s]\n",
      " 96%|█████████▌| 287/300 [09:40<00:20,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182212\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.12\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 135.38it/s]\n",
      " 96%|█████████▌| 288/300 [09:42<00:18,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182213\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.13\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 134.60it/s]\n",
      " 96%|█████████▋| 289/300 [09:43<00:17,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182215\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.15\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 130.42it/s]\n",
      " 97%|█████████▋| 290/300 [09:45<00:15,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182216\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.16\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.83it/s]\n",
      " 97%|█████████▋| 291/300 [09:46<00:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182218\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.18\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.11it/s]\n",
      " 97%|█████████▋| 292/300 [09:48<00:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182220\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.20\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.20\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 131.93it/s]\n",
      " 98%|█████████▊| 293/300 [09:49<00:11,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182221\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.21\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.54it/s]\n",
      " 98%|█████████▊| 294/300 [09:51<00:09,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182223\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.23\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.72it/s]\n",
      " 98%|█████████▊| 295/300 [09:53<00:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182224\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.24\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 129.20it/s]\n",
      " 99%|█████████▊| 296/300 [09:54<00:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182226\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.26\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.66it/s]\n",
      " 99%|█████████▉| 297/300 [09:56<00:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182227\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.27\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.17it/s]\n",
      " 99%|█████████▉| 298/300 [09:57<00:03,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182229\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.29\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 132.34it/s]\n",
      "100%|█████████▉| 299/300 [09:59<00:01,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-15 18:22.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/20250415181231_online_training_20250415182231\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.31\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-15 18:22.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [48], 'action_size': 4, 'config': {'type': 'double_dqn', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 5e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 1000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 133.77it/s]\n",
      "100%|██████████| 300/300 [10:01<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from online_main import online_training\n",
    "\n",
    "hyperparams = {\n",
    "        \"env\": \"CliffWalking-v0\", #\"CartPole-v0\", # \"Acrobot-v0\", \"MountainCar-v0\", \"FrozenLake-v1\", Pendulum-v1, \"CliffWalking-v0\", \"Taxi-v3\", \"RepresentedPong-v0\"\n",
    "        \"seed\": 42069,\n",
    "        # \"n_episodes\": 200,#5000,\n",
    "        \"max_episode_len\": 200, # Around 10h per 100k steps in Leviathan server\n",
    "        \"eps\": 0.1,  # epsilon for exploration\n",
    "        \"n_exp\": 1,\n",
    "        \"n_pretrain_eps\": 10,\n",
    "        \"n_online_eps\": 190, #10-290 for mountainCar, 30-170 for CartPole\n",
    "        \"gpu\": True, # True if use GPU to train with d3rlpy\n",
    "        \"buffer_size\": 100000, #Test with 100k, 200k, 500k. 1M might be too much\n",
    "        \"data_path\": None,#'data/CartPole_Qwen2.5-7B-Instruct_Neps_10_20250406040150.pkl',\n",
    "        \"model_path\": None,#'d3rlpy_loss/DoubleDQN_online_20250331153346/model_600000.d3',\n",
    "        \"batch_size\":256, #Test smaller batch size: 32, 64. May be noisier\n",
    "        \"learning_rate\":5e-5,\n",
    "        \"gamma\":0.99,\n",
    "        \"target_update_interval\":1000 #Test with 1k, 2k, 5k\n",
    "    }\n",
    "\n",
    "if \"Represented\" in hyperparams[\"env\"]:\n",
    "    env = GymCompatWrapper2(gym.make(hyperparams[\"env\"]))\n",
    "    eval_env = GymCompatWrapper2(gym.make(hyperparams[\"env\"]))\n",
    "elif isinstance(gym.make(hyperparams[\"env\"]).observation_space, gym.spaces.Discrete):\n",
    "    env = OneHotWrapper(gym.make(hyperparams[\"env\"]))\n",
    "    eval_env = OneHotWrapper(gym.make(hyperparams[\"env\"]))\n",
    "else:\n",
    "    env = gym.make(hyperparams[\"env\"], max_episode_steps=200)\n",
    "    eval_env = gym.make(hyperparams[\"env\"], max_episode_steps=200)\n",
    "\n",
    "# fix seed\n",
    "d3rlpy.seed(hyperparams[\"seed\"])\n",
    "d3rlpy.envs.seed_env(env, hyperparams[\"seed\"])\n",
    "d3rlpy.envs.seed_env(eval_env, hyperparams[\"seed\"])\n",
    "\n",
    "# explorer = d3rlpy.algos.ConstantEpsilonGreedy(hyperparams['eps'])\n",
    "explorer = d3rlpy.algos.LinearDecayEpsilonGreedy(\n",
    "    start_epsilon=1,\n",
    "    end_epsilon=0.1,\n",
    "    duration=5000,\n",
    ")\n",
    "print(env.observation_space)\n",
    "out = online_training(env, eval_env, hyperparams, explorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a7f704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc7138b7f70>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700acf4-9af5-46f8-9fcf-24e3b7d8d2cd",
   "metadata": {},
   "source": [
    "### Static/pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0488c-3f4d-43e2-a0c2-fd3a0d88b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250408032240_withEps.pkl\", 'rb') as file:\n",
    "#     Qwen_7B_dataset = pickle.load(file)\n",
    "\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250408120007_withEps.pkl\", 'rb') as file:\n",
    "#     Qwen_32B_dataset = pickle.load(file)\n",
    "\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250407113942.pkl\", 'rb') as file:\n",
    "#     Qwen_7B_dataset = pickle.load(file)\n",
    "\n",
    "# with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250407125034.pkl\", 'rb') as file:\n",
    "#     Qwen_32B_dataset = pickle.load(file)\n",
    "\n",
    "# This is the CartPole-v0 llm data with 0.1 eps\n",
    "with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-7B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250409023954E.pkl\", 'rb') as file:\n",
    "    Qwen_7B_dataset = pickle.load(file)\n",
    "\n",
    "with open(f\"data/{hyperparams['env'].split('-')[0]}_Qwen2.5-32B-Instruct_Neps_{hyperparams['n_pretrain_eps']}_20250409124533E.pkl\", 'rb') as file:\n",
    "    Qwen_32B_dataset = pickle.load(file)\n",
    "\n",
    "Qwen_32B_rewards = []\n",
    "for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "    Qwen_32B_rewards.append(Qwen_32B_dataset.episodes[i].compute_return())\n",
    "Qwen_7B_rewards = []\n",
    "for i in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "    Qwen_7B_rewards.append(Qwen_7B_dataset.episodes[i].compute_return())\n",
    "\n",
    "Qwen_7B = Qwen_7B_rewards + hyperparams[\"n_online_eps\"] * [np.mean(Qwen_7B_rewards)]\n",
    "Qwen_32B = Qwen_32B_rewards + hyperparams[\"n_online_eps\"] * [np.mean(Qwen_32B_rewards)]\n",
    "\n",
    "print(\"Qwen_32B: \", np.mean(Qwen_7B_rewards))\n",
    "print(\"Qwen_7B: \", np.mean(Qwen_32B_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa3e7b",
   "metadata": {},
   "source": [
    "### Generate and evaluate random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1009e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the random policy manually\n",
    "random_rewards = []\n",
    "for _ in range(hyperparams[\"n_pretrain_eps\"]):\n",
    "\tobs, _ = env.reset()\n",
    "\tdone = False\n",
    "\ttotal_reward = 0\n",
    "\tcount = 0\n",
    "\twhile not done:\n",
    "\t\taction = env.action_space.sample()\n",
    "\t\tobs, reward, done, _, _ = env.step(action)\n",
    "\t\ttotal_reward += reward\n",
    "\t\tcount += 1\n",
    "\t\tif count >= hyperparams[\"max_episode_len\"]:\n",
    "\t\t\tbreak\n",
    "\trandom_rewards.append(total_reward)\n",
    "\n",
    "mean_random = np.ones(hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]) * np.mean(random_rewards)\n",
    "# Print the average reward of the random policy\n",
    "print(f\"Average reward for random policy: {mean_random[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce761fef",
   "metadata": {},
   "source": [
    "### Fine-tune and Online data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb42d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/cache_{hyperparams['env'].split('-')[0]}{hyperparams['n_pretrain_eps']}E.pkl\", 'rb') as file:\n",
    "    cache = pickle.load(file)\n",
    "\n",
    "online_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "finetune_7b_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "finetune_32b_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "pretrain_7b_1000_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "pretrain_32b_1000_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "pretrain_7b_3000_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "pretrain_32b_3000_returns = np.zeros((hyperparams[\"n_exp\"], hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"]))\n",
    "\n",
    "for i in range(hyperparams[\"n_exp\"]):\n",
    "    online_returns[i] = cache[f\"online_{i}\"]\n",
    "    for j in range(hyperparams[\"n_online_eps\"]):\n",
    "        finetune_7b_returns[i][hyperparams[\"n_pretrain_eps\"]+j] = cache[f\"finetune_7b_{i}\"][j]\n",
    "        finetune_32b_returns[i][hyperparams[\"n_pretrain_eps\"]+j] = cache[f\"finetune_32b_{i}\"][j]\n",
    "        pretrain_7b_1000_returns[i][hyperparams[\"n_pretrain_eps\"]+j] = cache[f\"pretrain_7b_1000_{i}\"][j]\n",
    "        pretrain_32b_1000_returns[i][hyperparams[\"n_pretrain_eps\"]+j] = cache[f\"pretrain_32b_1000_{i}\"][j]\n",
    "        pretrain_7b_3000_returns[i][hyperparams[\"n_pretrain_eps\"]+j] = cache[f\"pretrain_7b_3000_{i}\"][j]\n",
    "        pretrain_32b_3000_returns[i][hyperparams[\"n_pretrain_eps\"]+j] = cache[f\"pretrain_32b_3000_{i}\"][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778df60f-a837-4aec-a95a-7bb92e7ea615",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(hyperparams[\"n_pretrain_eps\"] + hyperparams[\"n_online_eps\"])\n",
    "\n",
    "mean_finetune_32b = np.mean(finetune_32b_returns, axis = 0)\n",
    "std_finetune_32b = np.std(finetune_32b_returns, axis = 0)\n",
    "mean_finetune_7b = np.mean(finetune_7b_returns, axis = 0)\n",
    "std_finetune_7b = np.std(finetune_7b_returns, axis = 0)\n",
    "mean_onl = np.mean(online_returns, axis = 0)\n",
    "std_onl = np.std(online_returns, axis = 0)\n",
    "mean_pretrain_32b_1000 = np.mean(pretrain_32b_1000_returns, axis = 0)\n",
    "std_pretrain_32b_1000 = np.std(pretrain_32b_1000_returns, axis = 0)\n",
    "mean_pretrain_7b_1000 = np.mean(pretrain_7b_1000_returns, axis = 0)\n",
    "std_pretrain_7b_1000 = np.std(pretrain_7b_1000_returns, axis = 0)\n",
    "mean_pretrain_32b_3000 = np.mean(pretrain_32b_3000_returns, axis = 0)\n",
    "std_pretrain_32b_3000 = np.std(pretrain_32b_3000_returns, axis = 0)\n",
    "mean_pretrain_7b_3000 = np.mean(pretrain_7b_3000_returns, axis = 0)\n",
    "std_pretrain_7b_3000 = np.std(pretrain_7b_3000_returns, axis = 0)\n",
    "\n",
    "mean_finetune_7b[:hyperparams[\"n_pretrain_eps\"]] = Qwen_7B[:hyperparams[\"n_pretrain_eps\"]]\n",
    "mean_finetune_32b[:hyperparams[\"n_pretrain_eps\"]] = Qwen_32B[:hyperparams[\"n_pretrain_eps\"]]\n",
    "mean_pretrain_32b_1000[:hyperparams[\"n_pretrain_eps\"]] = Qwen_32B[:hyperparams[\"n_pretrain_eps\"]]\n",
    "mean_pretrain_7b_1000[:hyperparams[\"n_pretrain_eps\"]] = Qwen_7B[:hyperparams[\"n_pretrain_eps\"]]\n",
    "mean_pretrain_32b_3000[:hyperparams[\"n_pretrain_eps\"]] = Qwen_32B[:hyperparams[\"n_pretrain_eps\"]]\n",
    "mean_pretrain_7b_3000[:hyperparams[\"n_pretrain_eps\"]] = Qwen_7B[:hyperparams[\"n_pretrain_eps\"]]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(mean_onl, label='On-policy')\n",
    "plt.fill_between(x, mean_onl-std_onl/np.sqrt(hyperparams[\"n_exp\"]), mean_onl+std_onl/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "plt.plot(mean_finetune_32b, label='Mix Qwen 32B')\n",
    "plt.fill_between(x, mean_finetune_32b-std_finetune_32b/np.sqrt(hyperparams[\"n_exp\"]), mean_finetune_32b+std_finetune_32b/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "plt.plot(mean_finetune_7b, label='Mix Qwen 7B')\n",
    "plt.fill_between(x, mean_finetune_7b-std_finetune_7b/np.sqrt(hyperparams[\"n_exp\"]), mean_finetune_7b+std_finetune_7b/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "plt.plot(mean_pretrain_32b_1000, label='Pretrain Qwen 32B 1000 steps')\n",
    "plt.fill_between(x, mean_pretrain_32b_1000-std_pretrain_32b_1000/np.sqrt(hyperparams[\"n_exp\"]), mean_pretrain_32b_1000+std_pretrain_32b_1000/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "plt.plot(mean_pretrain_7b_1000, label='Pretrain Qwen 7B 1000 steps')\n",
    "plt.fill_between(x, mean_pretrain_7b_1000-std_pretrain_7b_1000/np.sqrt(hyperparams[\"n_exp\"]), mean_pretrain_7b_1000 +std_pretrain_7b_1000/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "plt.plot(mean_pretrain_32b_3000, label='Pretrain Qwen 32B 3000 steps')\n",
    "plt.fill_between(x, mean_pretrain_32b_3000-std_pretrain_32b_3000/np.sqrt(hyperparams[\"n_exp\"]), mean_pretrain_32b_3000+std_pretrain_32b_3000/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "plt.plot(mean_pretrain_7b_3000, label='Pretrain Qwen 7B 3000 steps')\n",
    "plt.fill_between(x, mean_pretrain_7b_3000-std_pretrain_7b_3000/np.sqrt(hyperparams[\"n_exp\"]), mean_pretrain_7b_3000 +std_pretrain_7b_3000/np.sqrt(hyperparams[\"n_exp\"]), alpha=0.5)\n",
    "\n",
    "plt.plot(Qwen_7B, label='Qwen_7B', linestyle=':')\n",
    "plt.plot(Qwen_32B, label='Qwen_32B', linestyle=':')\n",
    "plt.plot(mean_random, label='Random', linestyle=':')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Sum episode reward for Double-DQN with {hyperparams[\"n_pretrain_eps\"]} eps data collection and {hyperparams[\"n_online_eps\"]} eps On-policy learning (#seed={hyperparams[\"n_exp\"]}) with std error.')\n",
    "plt.xlabel('# of episodes')\n",
    "plt.ylabel('Eps reward')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "# plt.xticks(np.arange(0, 101, 10))\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad431a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plt.plot(mean_onl, label='On-policy')\n",
    "# plt.fill_between(x, mean_onl-std_onl, mean_onl+std_onl, alpha=0.5)\n",
    "# plt.plot(mean_finetune_32b, label='Mix Qwen 32B')\n",
    "# plt.fill_between(x, mean_finetune_32b-std_finetune_32b, mean_finetune_32b+std_finetune_32b, alpha=0.5)\n",
    "# plt.plot(mean_finetune_7b, label='Mix Qwen 7B')\n",
    "# plt.fill_between(x, mean_finetune_7b-std_finetune_7b, mean_finetune_7b+std_finetune_7b, alpha=0.5)\n",
    "# plt.plot(mean_pretrain_32b_1000, label='Pretrain Qwen 32B 1000 steps')\n",
    "# plt.fill_between(x, mean_pretrain_32b_1000-std_pretrain_32b_1000, mean_pretrain_32b_1000+std_pretrain_32b_1000, alpha=0.5)\n",
    "# plt.plot(mean_pretrain_7b_1000, label='Pretrain Qwen 7B 1000 steps')\n",
    "# plt.fill_between(x, mean_pretrain_7b_1000-std_pretrain_7b_1000, mean_pretrain_7b_1000 +std_pretrain_7b_1000, alpha=0.5)\n",
    "# plt.plot(mean_pretrain_32b_3000, label='Pretrain Qwen 32B 3000 steps')\n",
    "# plt.fill_between(x, mean_pretrain_32b_3000-std_pretrain_32b_3000, mean_pretrain_32b_3000+std_pretrain_32b_3000, alpha=0.5)\n",
    "# plt.plot(mean_pretrain_7b_3000, label='Pretrain Qwen 7B 3000 steps')\n",
    "# plt.fill_between(x, mean_pretrain_7b_3000-std_pretrain_7b_3000, mean_pretrain_7b_3000 +std_pretrain_7b_3000, alpha=0.5)\n",
    "\n",
    "# plt.plot(Qwen_7B, label='Qwen_7B', linestyle=':')\n",
    "# plt.plot(Qwen_32B, label='Qwen_32B', linestyle=':')\n",
    "# plt.plot(mean_random, label='Random', linestyle=':')\n",
    "\n",
    "# # Customize the plot\n",
    "# plt.title(f'Sum episode reward for Double-DQN with {hyperparams[\"n_pretrain_eps\"]} eps data collection and {hyperparams[\"n_online_eps\"]} eps On-policy learning (#seed={hyperparams[\"n_exp\"]})')\n",
    "# plt.xlabel('# of episodes')\n",
    "# plt.ylabel('Eps reward')\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "# # plt.xticks(np.arange(0, 101, 10))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def moving_average(data, window_size):\n",
    "#     \"\"\"Compute moving average using convolution.\"\"\"\n",
    "#     window = np.ones(window_size) / window_size\n",
    "#     # return np.convolve(data, window, mode='valid')\n",
    "#     half_window = window_size // 2\n",
    "#     new_data = np.pad(data, (half_window, half_window), mode='reflect')  # Pad data to handle edges\n",
    "#     return np.convolve(new_data, window, mode='valid')\n",
    "\n",
    "# # Define the window size for smoothing\n",
    "# window_size = 5  # Adjust this value as needed\n",
    "\n",
    "# # Smooth the data\n",
    "# smoothed_mean_onl = moving_average(mean_onl, window_size)\n",
    "# smoothed_mean_finetune_32b = moving_average(mean_finetune_32b, window_size)\n",
    "# smoothed_mean_finetune_7b = moving_average(mean_finetune_7b, window_size)\n",
    "# smoothed_mean_pretrain_32b_1000 = moving_average(mean_pretrain_32b_1000, window_size)\n",
    "# smoothed_mean_pretrain_7b_1000 = moving_average(mean_pretrain_7b_1000, window_size)\n",
    "# smoothed_mean_pretrain_32b_3000 = moving_average(mean_pretrain_32b_3000, window_size)\n",
    "# smoothed_mean_pretrain_7b_3000 = moving_average(mean_pretrain_7b_3000, window_size)\n",
    "\n",
    "# # Adjust the x-axis range for the smoothed data\n",
    "# x_smooth = range(len(smoothed_mean_onl))\n",
    "\n",
    "# # Plot the smoothed results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plt.plot(x_smooth, smoothed_mean_onl, label='Smoothed On-policy')\n",
    "# plt.fill_between(x, smoothed_mean_onl-std_onl, smoothed_mean_onl+std_onl, alpha=0.5)\n",
    "# plt.plot(x_smooth, smoothed_mean_finetune_32b, label='Smoothed Mix Qwen 32B')\n",
    "# plt.fill_between(x, smoothed_mean_finetune_32b-std_finetune_32b, smoothed_mean_finetune_32b+std_finetune_32b, alpha=0.5)\n",
    "# plt.plot(x_smooth, smoothed_mean_finetune_7b, label='Smoothed Mix Qwen 7B')\n",
    "# plt.fill_between(x, smoothed_mean_finetune_7b-std_finetune_7b, smoothed_mean_finetune_7b+std_finetune_7b, alpha=0.5)\n",
    "# plt.plot(smoothed_mean_pretrain_32b_1000, label='Smoothed Pretrain Qwen 32B 1000 steps')\n",
    "# plt.fill_between(x, smoothed_mean_pretrain_32b_1000-std_pretrain_32b_1000, smoothed_mean_pretrain_32b_1000+std_pretrain_32b_1000, alpha=0.5)\n",
    "# plt.plot(smoothed_mean_pretrain_7b_1000, label='Smoothed Pretrain Qwen 7B 1000 steps')\n",
    "# plt.fill_between(x, smoothed_mean_pretrain_7b_1000-std_pretrain_7b_1000, smoothed_mean_pretrain_7b_1000 +std_pretrain_7b_1000, alpha=0.5)\n",
    "# plt.plot(smoothed_mean_pretrain_32b_3000, label='Smoothed Pretrain Qwen 32B 3000 steps')\n",
    "# plt.fill_between(x, smoothed_mean_pretrain_32b_3000-std_pretrain_32b_3000, smoothed_mean_pretrain_32b_3000+std_pretrain_32b_3000, alpha=0.5)\n",
    "# plt.plot(smoothed_mean_pretrain_7b_3000, label='Smoothed Pretrain Qwen 7B 3000 steps')\n",
    "# plt.fill_between(x, smoothed_mean_pretrain_7b_3000-std_pretrain_7b_3000, smoothed_mean_pretrain_7b_3000 +std_pretrain_7b_3000, alpha=0.5)\n",
    "\n",
    "# plt.plot(Qwen_7B, label='Qwen_7B', linestyle=':')\n",
    "# plt.plot(Qwen_32B, label='Qwen_32B', linestyle=':')\n",
    "# plt.plot(mean_random, label='Random', linestyle=':')\n",
    "\n",
    "# # Customize the plot\n",
    "# plt.title(f'Smoothed sum episode reward for Double-DQN with {hyperparams[\"n_pretrain_eps\"]} eps data collection and {hyperparams[\"n_online_eps\"]} eps On-policy learning (#seed={hyperparams[\"n_exp\"]})')\n",
    "# plt.xlabel('# of episodes')\n",
    "# plt.ylabel('Eps reward')\n",
    "# # plt.grid(True)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "# # plt.xticks(np.arange(0, 101, 10))\n",
    "# # plt.legend()\n",
    "# # plt.grid(True)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamagym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
